{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTap - UPDRS-Tapping Assessment - Predictions\n",
    "\n",
    "This notebooks investigates optimal hand- and fingertapping algorithms as part of the \n",
    "ReTune-Dyskinesia project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from array import array\n",
    "import datetime as dt\n",
    "from dataclasses import  dataclass, field\n",
    "from itertools import compress\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 1.4.4\n",
      "numpy 1.23.3\n",
      "sci-py 1.9.1\n",
      "sci-kit learn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "\n",
    "\n",
    "## developed with:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1\n",
    "\n",
    "## Currently (own env) since 31.08.22\n",
    "# Python sys 3.9.12 (main, Jun  1 2022, 06:36:29) \n",
    "# [Clang 12.0.0 ]\n",
    "# pandas 1.4.3\n",
    "# numpy 1.21.5\n",
    "# sci-py 1.7.3\n",
    "# sci-kit learn 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own functions\n",
    "from retap_utils import utils_dataManagement\n",
    "import retap_utils.get_datasplit as get_split\n",
    "\n",
    "import tap_predict.tap_pred_prepare as pred_prep\n",
    "import tap_predict.tap_pred_help as pred_help\n",
    "import tap_plotting.retap_plot_clusters as plot_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split development and hold-out-test data sets\n",
    "\n",
    "- Development data is used to train and test the model using iterative cross-validation\n",
    "- Hold-out test data is NOT USED at all during cross-validation, and will be used to test the trained model as an external validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT CREATED CLASSES FROM FILES\n",
    "\n",
    "# import of feature classes is mandatory to use pickle below\n",
    "from tap_extract_fts.main_featExtractionClass import FeatureSet, singleTrace\n",
    "\n",
    "# define path with feature class\n",
    "deriv_path = os.path.join(utils_dataManagement.get_local_proj_dir(), 'data', 'derivatives')\n",
    "\n",
    "# ftClass = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_20221214.P'))\n",
    "# ftClass10 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_max10_20221214.P'))\n",
    "\n",
    "# newFts = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_20230301.P'))\n",
    "# newFts10 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_max10_20230228.P'))\n",
    "newFts15 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_max15_20230228.P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 18 included SUBS for BER\n",
      "# 311 included TRACES for BER\n",
      "# 19 included SUBS for DUS\n",
      "# 65 included TRACES for DUS\n"
     ]
    }
   ],
   "source": [
    "subs = []\n",
    "for t in newFts.incl_traces:\n",
    "    subs.append(getattr(newFts, t).sub)\n",
    "\n",
    "unique_subs = list(set(subs))\n",
    "\n",
    "for cen in ['BER', 'DUS']:\n",
    "    n = sum([cen in t for t in unique_subs])\n",
    "    print(f'# {n} included SUBS for {cen}')\n",
    "    n = sum([cen in t for t in newFts.incl_traces])\n",
    "    print(f'# {n} included TRACES for {cen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER023_M1S0_R_2\n"
     ]
    }
   ],
   "source": [
    "for t in newFts.incl_traces:\n",
    "    if getattr(newFts, t).tap_score == 4:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=0.24963841694578337, pvalue=0.6173297943179522)\n",
      "MannwhitneyuResult(statistic=12246.0, pvalue=0.6177675167728323)\n"
     ]
    }
   ],
   "source": [
    "### test distribution\n",
    "\n",
    "dev_scores = []\n",
    "dev_scores.extend(28 * [0])\n",
    "dev_scores.extend(106 * [1])\n",
    "dev_scores.extend(74 * [2])\n",
    "dev_scores.extend(40 * [0])\n",
    "\n",
    "val_scores = []\n",
    "val_scores.extend(12 * [0])\n",
    "val_scores.extend(43 * [1])\n",
    "val_scores.extend(33 * [2])\n",
    "val_scores.extend(14 * [0])\n",
    "\n",
    "print(stats.kruskal(dev_scores, val_scores)\n",
    ")\n",
    "print(stats.mannwhitneyu(dev_scores, val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ML-dataset Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble method: 1) score too few taps as 3, 2) cluster on tapping-frequency features, 3) K-Fold cv of Classification model\n",
    "\n",
    "Create X1 with selected input features (mean and coef of variation of intra-tap-interval) and\n",
    "overall tapping frequency to find two clusters (y_clusters) dividing fast vs slow tappers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for classification method\n",
    "MAX_TAPS_PER_TRACE = 15\n",
    "USE_FT_CLASS = newFts15\n",
    "DATASPLIT = 'HOLDOUT'  # should be CROSSVAL or HOLDOUT\n",
    "N_RANDOM_SPLIT = 125   #41  # 01.03.23\n",
    "\n",
    "SUBS_EXCL = ['BER028']  # too many missing acc-data\n",
    "TRACES_EXCL = ['DUS006_M0S0_L_1', 'BER023_M1S0_R_2',\n",
    "               'DUS017_M1S0_L_1', 'DUS017_M1S1_L_1',\n",
    "               ]\n",
    "\n",
    "SCORE_FEW_TAPS_3 = True\n",
    "CUTOFF_TAPS_3 = 9\n",
    "\n",
    "CLUSTER_ON_FREQ = False\n",
    "N_CLUSTERS_FEQ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK FOR MISSING ACC DATA IN TRACES\n",
    "# for t in newFts.incl_traces:\n",
    "\n",
    "#     sig = getattr(newFts, t).acc_sig\n",
    "#     nan_ratio = sum(np.isnan(sig).any(axis=0)) / sig.shape[1]\n",
    "\n",
    "#     if nan_ratio > 0: print(t, nan_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excl sub: BER028, led to 24 excl traces\n"
     ]
    }
   ],
   "source": [
    "excl_sub = 'BER028'\n",
    "excl_sub_traces = [t for t in newFts.incl_traces if t.startswith(excl_sub)]\n",
    "print(f'excl sub: {excl_sub}, led to {len(excl_sub_traces)} excl traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING DATA IN DEV AND HOLD-OUT\n",
      "Original score distribution: {0: 40, 1: 146, 2: 107, 3: 53, 4: 2}\n",
      "Original score %: {0: 11.5, 1: 42.0, 2: 30.7, 3: 15.2, 4: 0.6}\n",
      "Accepted Split: random state 125\n",
      "\n",
      "Resulting distributions in splitted data sets:\n",
      "\n",
      "\tdev data set (n = 249):\n",
      "score 0: # 28 (11 %)\n",
      "score 1: # 106 (43 %)\n",
      "score 2: # 75 (30 %)\n",
      "score 3: # 39 (16 %)\n",
      "score 4: # 1 (0 %)\n",
      "\thout data set (n = 103):\n",
      "score 0: # 12 (12 %)\n",
      "score 1: # 42 (41 %)\n",
      "score 2: # 33 (32 %)\n",
      "score 3: # 14 (14 %)\n",
      "score 4: # 2 (2 %)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(get_split)\n",
    "\n",
    "### GET DATA SPLIT CROSS-VAL OR HOLD-OUT\n",
    "# get dict with dev and hold-out datasets\n",
    "datasplit_subs = get_split.find_dev_holdout_split(\n",
    "    feats=USE_FT_CLASS,\n",
    "    subs_excl=SUBS_EXCL,\n",
    "    traces_excl=TRACES_EXCL,\n",
    "    choose_random_split=N_RANDOM_SPLIT,\n",
    ")\n",
    "\n",
    "if DATASPLIT == 'CROSSVAL': SUBS_EXCL.extend(datasplit_subs['hout'])\n",
    "elif DATASPLIT == 'HOLDOUT': SUBS_EXCL.extend(datasplit_subs['dev'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform AFTER data split\n",
    "if SCORE_FEW_TAPS_3:\n",
    "    (\n",
    "        classf_taps_3,\n",
    "        y_pred_fewTaps,\n",
    "        y_true_fewTaps\n",
    "    ) = pred_help.classify_based_on_nTaps(\n",
    "        max_n_taps=CUTOFF_TAPS_3,\n",
    "        ftClass=USE_FT_CLASS,\n",
    "        # in_cv=True\n",
    "    )\n",
    "    # select traces from subs present in current datasplit\n",
    "    if DATASPLIT == 'CROSSVAL':\n",
    "        datasplit_sel = [\n",
    "            np.array([t.startswith(s) for s in datasplit_subs['dev']]).any()\n",
    "            for t in classf_taps_3\n",
    "        ]\n",
    "    elif DATASPLIT == 'HOLDOUT':\n",
    "        datasplit_sel = [\n",
    "            np.array([t.startswith(s) for s in datasplit_subs['hout']]).any()\n",
    "            for t in classf_taps_3\n",
    "        ]\n",
    "    \n",
    "    TRACES_EXCL.extend(list(compress(classf_taps_3, datasplit_sel)))\n",
    "    y_pred_fewTaps = list(compress(y_pred_fewTaps, datasplit_sel))\n",
    "    y_true_fewTaps = list(compress(y_true_fewTaps, datasplit_sel))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make X input Matrix with more features for score-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed slope_intraTapInt into absolute values\n",
      "transformed slope_tap_entropy into absolute values\n",
      "(96, 14)\n",
      "# of NaNs per feat: [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "to_mask_4 = True\n",
    "to_mask_0 = False\n",
    "to_zscore = True\n",
    "to_norm = False\n",
    "\n",
    "CLASS_FEATS = [\n",
    "    'trace_RMSn',\n",
    "    'trace_entropy',\n",
    "    'jerkiness_trace',\n",
    "\n",
    "    'coefVar_intraTapInt',\n",
    "    'slope_intraTapInt',\n",
    "    'mean_tapRMS',\n",
    "    'coefVar_tapRMS',\n",
    "    'mean_impactRMS',\n",
    "    'coefVar_impactRMS',\n",
    "    'slope_impactRMS',\n",
    "    'mean_raise_velocity',\n",
    "    'coefVar_raise_velocity',\n",
    "    'coefVar_tap_entropy',\n",
    "    'slope_tap_entropy',\n",
    "\n",
    "    # 'decr_intraTapInt',\n",
    "    # 'mean_intraTapInt',  # out bcs of clustering (in for non-clustering)\n",
    "    # 'decr_tapRMS',  # bcs slope dont steadily incr or decr\n",
    "    # 'slope_tapRMS',\n",
    "    # 'decr_raise_velocity',\n",
    "    # 'slope_raise_velocity',\n",
    "\n",
    "]\n",
    "\n",
    "cv_data = pred_prep.create_X_y_vectors(\n",
    "    USE_FT_CLASS,\n",
    "    incl_traces=USE_FT_CLASS.incl_traces,\n",
    "    incl_feats=CLASS_FEATS,\n",
    "    excl_traces=TRACES_EXCL,\n",
    "    excl_subs=SUBS_EXCL,  # due to hold out data set\n",
    "    to_norm=to_norm,\n",
    "    to_zscore=to_zscore,\n",
    "    to_mask_4=to_mask_4,\n",
    "    return_ids=True,\n",
    "    as_class=True,\n",
    "    mask_nans=True,\n",
    ")\n",
    "\n",
    "# create final dataframe with true and ensemble-predicted labels\n",
    "# default all NaN's, filled during ensemble prediction\n",
    "overall_perf = pd.DataFrame(\n",
    "    data=np.array([[np.nan] * len(cv_data.y)] * 2).T,\n",
    "    columns=['y_true', 'y_pred'],\n",
    "    index=cv_data.ids,\n",
    ")\n",
    "overall_perf['y_true'] = cv_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing features (if nans are not masked above)\n",
    "# for i, trace in enumerate(cv_data.ids):\n",
    "\n",
    "#     if np.isnan(cv_data.X[i, :]).any():\n",
    "#         print(trace,\n",
    "#               np.array(CLASS_FEATS)[np.isnan(cv_data.X[i, :])])\n",
    "#         print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONALLY. Split input matrix X_2 in two generated clusters:\n",
    "- split X and y in two groups based on clusters\n",
    "- test default ML modeling on both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs per feat: [0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcluster 0: -0.44354326588319587\n",
      "\tcluster 1: 1.4251554116902685\n",
      "Fast X shape: (196, 14), Slow X shape: (61, 14)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "importlib.reload(get_split)\n",
    "importlib.reload(plot_cluster)\n",
    "importlib.reload(pred_help)\n",
    "\n",
    "# set variables for pre-clustering\n",
    "\n",
    "\n",
    "CLUSTER_FEATS = [\n",
    "    'mean_intraTapInt',\n",
    "    'coefVar_intraTapInt',\n",
    "    'freq'\n",
    "]\n",
    "to_mask_4 = True\n",
    "to_mask_0 = False\n",
    "to_zscore = True\n",
    "to_norm = False\n",
    "\n",
    "# # get dict with dev and hold-out datasets\n",
    "# datasplit_subs = get_split.find_dev_holdout_split(\n",
    "#     feats=USE_FT_CLASS,\n",
    "#     subs_excl=SUBS_EXCL,\n",
    "#     traces_excl=traces_excl,\n",
    "#     choose_random_split=N_RANDOM_SPLIT\n",
    "# )\n",
    "\n",
    "# subs_excl_total = datasplit_subs['hout'].copy()  # both bcs of hold out\n",
    "# subs_excl_total.extend(SUBS_EXCL)  # and bcs of a priori excl\n",
    "\n",
    "# create dataclass for clustering (input matrix, label vector)\n",
    "# only include dev, exclude hold-out\n",
    "cluster_data = pred_prep.create_X_y_vectors(\n",
    "    ftClass=USE_FT_CLASS,\n",
    "    incl_feats=CLUSTER_FEATS,\n",
    "    incl_traces=USE_FT_CLASS.incl_traces,\n",
    "    excl_traces=TRACES_EXCL,\n",
    "    excl_subs=SUBS_EXCL,  # excl hold out data\n",
    "    to_zscore=to_zscore,\n",
    "    to_norm=to_norm,\n",
    "    to_mask_4=to_mask_4,\n",
    "    to_mask_0=to_mask_0,\n",
    "    return_ids=True,\n",
    "    as_class=True\n",
    ")\n",
    "\n",
    "# create cluster labels\n",
    "y_clusters, centr_clust, _ = plot_cluster.get_kMeans_clusters(\n",
    "    X=cluster_data.X,\n",
    "    n_clusters=N_CLUSTERS_FEQ,\n",
    "    use_pca=True,\n",
    "    to_zscore=to_zscore,\n",
    "    to_norm=to_norm,\n",
    ")\n",
    "\n",
    " # split pred_data in two clusters\n",
    "(cv_fast_data, cv_slow_data) = pred_help.split_data_in_clusters(\n",
    "    cv_data, y_clusters, cluster_data, CLUSTER_FEATS\n",
    ")\n",
    "print(f'Fast X shape: {cv_fast_data.X.shape}, Slow X shape: {cv_slow_data.X.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise features in specific clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PUT IN PLOTTING MODULE\n",
    "\n",
    "# create lists for boxplots of features per subscore, per cluster\n",
    "\n",
    "temp_data = cv_data\n",
    "\n",
    "# plot present tap-scores\n",
    "temp_data_scores = [getattr(USE_FT_CLASS, t).tap_score for t in temp_data.ids]\n",
    "temp_data_scores = [getattr(USE_FT_CLASS, t).tap_score for t in temp_data.ids]\n",
    "score_counts = {y: temp_data_scores.count(y) for y in set(temp_data_scores)}\n",
    "plt.bar(score_counts.keys(), score_counts.values())\n",
    "plt.close()\n",
    "\n",
    "box_lists = {}\n",
    "for f in range(temp_data.X.shape[1]):\n",
    "    box_lists[f] = {}\n",
    "    for i in range(4): box_lists[f][i] = []\n",
    "\n",
    "\n",
    "for i in np.arange(temp_data.X.shape[0]):\n",
    "\n",
    "    score = temp_data.y[i]\n",
    "\n",
    "    for f in range(temp_data.X.shape[1]):\n",
    "\n",
    "        if np.logical_and(\n",
    "            CLASS_FEATS[f].startswith('slope') or CLASS_FEATS[f].startswith('decr'),\n",
    "            'entr' in CLASS_FEATS[f] or 'jerk' in CLASS_FEATS[f] or 'intraTap' in CLASS_FEATS[f]\n",
    "        ):\n",
    "            box_lists[f][int(score)].append(abs(temp_data.X[i, f]))\n",
    "\n",
    "        else:\n",
    "            box_lists[f][int(score)].append(temp_data.X[i, f])\n",
    "\n",
    "# plot features within cluster, and decide on strategy\n",
    "# pm: use pre-knowledge about clusters\n",
    "# likelihood in faster cluster for 1-2 scores\n",
    "# use probabilities and adapt the threshold for acceptance\n",
    "# start finding border scores (e.g. 1 or 3)\n",
    "\n",
    "for i_f, ft in enumerate(CLASS_FEATS):\n",
    "\n",
    "    plot_lists = [box_lists[i_f][i] for i in range(4)]\n",
    "\n",
    "    plt.boxplot(plot_lists)\n",
    "    plt.title(ft)\n",
    "    plt.xticks(range(1, len(plot_lists) + 1), labels=['0', '1', '2', '3+4'])\n",
    "    plt.xlabel('UPDRS tap-score')\n",
    "    plt.ylabel('Z-score (a.u.)')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test hierarchichal prediction with Random Forest\n",
    "\n",
    "- Boolean Classification seemed inferior compared to MultiClass RF\n",
    "\n",
    "    optimal thresholds (to prevent too large False Positive Values)\n",
    "    predicting the best tappers (0-1)\n",
    "    - (best) RandomForest, cutoff .75 (TPR ~ .75-.8, FPR ~ .15)\n",
    "    - .58 - .6 for LogReg\n",
    "    - .6 for svm linear kernel\n",
    "    - .6 for svm poly kernel\n",
    "\n",
    "    indicating updrs 3 chance for next step\n",
    "    - .15 for log reg and lda (svc not succesful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tap_predict import retap_cv_models as cv_models\n",
    "from tap_plotting import plot_cv_folds as plot_folds\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Fast Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score as kappa  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 130, test 66\n",
      "Fold 1: # of samples: train 131, test 65\n",
      "Fold 2: # of samples: train 131, test 65\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_fast_data  # data to use here\n",
    "score_to_predict = 3\n",
    "clf_choice = 'RF'\n",
    "nFolds = 3\n",
    "to_plot = True\n",
    "\n",
    "multiclass = True\n",
    "\n",
    "if multiclass:\n",
    "    y_pred_true = temp_data.y\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "else:\n",
    "    if score_to_predict == 1:\n",
    "        y_pred_true = temp_data.y <= score_to_predict\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        y_pred_true = temp_data.y == score_to_predict\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    " y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_pred_true,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "# mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "# print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "#         f' (+/- {round(std_pen, 2)})')\n",
    "# y_true_temp, y_pred_temp = [], []\n",
    "\n",
    "# for f in np.arange(len(y_true_dict)):\n",
    "#     y_true_temp.extend(y_true_dict[f])\n",
    "#     y_pred_temp.extend(y_pred_dict[f])\n",
    "\n",
    "# k_score = kappa(y_true_temp, y_pred_temp, weights='linear')\n",
    "# fast_true = y_true_temp\n",
    "# fast_pred = y_pred_temp\n",
    "\n",
    "# print(f'Kappa: {k_score}, '\n",
    "#       f'R: {scipy.stats.spearmanr(y_true_temp, y_pred_temp)}')\n",
    "\n",
    "# jitt = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# jitt2 = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# plt.scatter(y_true_temp+jitt, y_pred_temp+jitt2)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Slow Tapper Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included # of traces: 61\n",
      "\tscore 0: # 5 (8 %)\n",
      "\tscore 1: # 12 (20 %)\n",
      "\tscore 2: # 24 (39 %)\n",
      "\tscore 3: # 20 (33 %)\n",
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 40, test 21\n",
      "Fold 1: # of samples: train 41, test 20\n",
      "Fold 2: # of samples: train 41, test 20\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_slow_data  # data to use here\n",
    "clf_choice = 'RF'\n",
    "nFolds = 3\n",
    "mask_0 = False\n",
    "multiclass = True\n",
    "score_to_predict = 3\n",
    "\n",
    "y_model = temp_data.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model == score_to_predict\n",
    "    to_plot = True\n",
    "\n",
    "    if score_to_predict == 1:\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "# print descriptives\n",
    "n_samples = len(temp_data.ids)\n",
    "print(f'Included # of traces: {n_samples}')\n",
    "y_scores, counts = np.unique(y_model, return_counts=True)\n",
    "for s, c in zip(y_scores, counts):\n",
    "    print(f'\\tscore {s}: # {c} ({round(c / n_samples * 100)} %)')\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    " y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_model,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "# mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "# print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "#         f' (+/- {round(std_pen, 2)})')\n",
    "\n",
    "\n",
    "\n",
    "# y_true_temp, y_pred_temp = [], []\n",
    "\n",
    "# for f in np.arange(len(y_true_dict)):\n",
    "#     y_true_temp.extend(y_true_dict[f])\n",
    "#     y_pred_temp.extend(y_pred_dict[f])\n",
    "\n",
    "# k_score = kappa(y_true_temp, y_pred_temp, weights='linear')\n",
    "# slow_true = y_true_temp\n",
    "# slow_pred = y_pred_temp\n",
    "\n",
    "# print(f'Kappa: {k_score}, '\n",
    "#       f'R: {scipy.stats.spearmanr(y_true_temp, y_pred_temp)}')\n",
    "\n",
    "# jitt = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# jitt2 = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# plt.scatter(y_true_temp+jitt, y_pred_temp+jitt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### COMBINE FAST AND SLOW CLUSTER OUTCOMES\n",
    "\n",
    "# true_clusters = [l for l in [fast_true, slow_true, y_true_fewTaps]]\n",
    "# true_clusters = [s for l in true_clusters for s in l]\n",
    "\n",
    "# pred_clusters = [l for l in [fast_pred, slow_pred, y_pred_fewTaps]]\n",
    "# pred_clusters = [s for l in pred_clusters for s in l]\n",
    "\n",
    "# cm = cv_models.multiclass_conf_matrix(\n",
    "#       y_true=true_clusters, y_pred=pred_clusters,\n",
    "#       labels=mc_labels,\n",
    "# )\n",
    "# print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "# mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "# print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "#         f' (+/- {round(std_pen, 2)})')\n",
    "\n",
    "# print(f'Kappa: {k_score}, '\n",
    "#       f'R: {scipy.stats.spearmanr(true_clusters, pred_clusters)}')\n",
    "\n",
    "# jitt = np.random.uniform(low=-.2, high=0.2, size=len(true_clusters))\n",
    "# jitt2 = np.random.uniform(low=-.2, high=0.2, size=len(pred_clusters))\n",
    "# plt.scatter(true_clusters+jitt, pred_clusters+jitt2)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# im = ax.imshow(cm.values)\n",
    "\n",
    "# # Show all ticks and label them with the respective list entries\n",
    "# ax.xaxis.tick_top()\n",
    "# ax.set_xticks(np.arange(len(mc_labels)))\n",
    "# ax.set_yticks(np.arange(len(mc_labels)))\n",
    "# ax.set_xticklabels(mc_labels, weight='bold', fontsize=fs)\n",
    "# ax.set_yticklabels(mc_labels, weight='bold', fontsize=fs, )\n",
    "# ax.xaxis.set_label_position('top')\n",
    "# ax.set_xlabel('True UPDRS Tap Score', weight='bold', fontsize=fs, )\n",
    "# ax.set_ylabel('Predicted UPDRS Tap Score', weight='bold', fontsize=fs)\n",
    "\n",
    "# # Loop over data dimensions and create text annotations.\n",
    "# for i in range(len(mc_labels)):\n",
    "#     for j in range(len(mc_labels)):\n",
    "#         value = cm.values[i, j]\n",
    "#         if value > 30: txt_col ='k'\n",
    "#         else: txt_col = 'w'\n",
    "#         text = ax.text(\n",
    "#             j, i, value, weight='bold', fontsize=fs,\n",
    "#             ha=\"center\", va=\"center\", color=txt_col,\n",
    "#       )\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test all Tappers (without clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "ADD_FEW_TAPS = True\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_data  # data to use here\n",
    "clf_choice = 'RF'\n",
    "nFolds = 6\n",
    "mask_0 = False\n",
    "multiclass = True\n",
    "score_to_predict = 3\n",
    "to_plot=True\n",
    "\n",
    "y_model = temp_data.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model == score_to_predict\n",
    "    to_plot = True\n",
    "\n",
    "    if score_to_predict == 1:\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    "y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_model,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    "    verbose=False,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "        # verbose=False,\n",
    "    )\n",
    "if multiclass:\n",
    "\n",
    "    if ADD_FEW_TAPS:\n",
    "        n_dict = nFolds\n",
    "        y_true_dict[n_dict] = y_true_fewTaps\n",
    "        y_pred_dict[n_dict] = y_pred_fewTaps\n",
    "\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tap_plotting.plot_pred_results as plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(plot_results)\n",
    "# y_true_temp, y_pred_temp = [], []\n",
    "\n",
    "# for f in np.arange(len(y_true_dict)):\n",
    "#     y_true_temp.extend(y_true_dict[f])\n",
    "#     y_pred_temp.extend(y_pred_dict[f])\n",
    "\n",
    "# k_score = kappa(y_true_temp, y_pred_temp, weights='linear')\n",
    "# R, R_p = scipy.stats.spearmanr(y_true_temp, y_pred_temp)\n",
    "\n",
    "\n",
    "\n",
    "# plot_results.plot_confMatrix_scatter(\n",
    "#     y_true_temp, y_pred_temp,\n",
    "#     R=R, K=k_score, CM=cm,\n",
    "#     to_save=False, to_show=True, fname='Unclustered'\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) PM Traditional Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Candidate vetors based on descriptives and concept\n",
    "    - nTaps\n",
    "    - freq\n",
    "    - upVelo sum [std-dev + coefVar]\n",
    "    - impact RMS [coefVar + stddev]\n",
    "    - tapRMS and impactRMS [sum]\n",
    "    - \n",
    "- include per run (array tap-features): sum, mean, stddev, trend_slope\n",
    "\n",
    "- Cluster on UPDRS 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANOVA\n",
    "\n",
    "- normality assumption violated (Shapiro test highly significant)\n",
    "- for every a priori selected feature: present difference between sub-score-groups is a Kruskal-Wallis test (non-parametric One-Way ANOVA alternative)\n",
    "- differences between two sub groups within a feature is a non-parametric test of two groups of quantitative values (likely varying lengths): Mann-Whitney-U\n",
    "- in total: correct alpha for number of repeated measures on specific level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import shapiro\n",
    "# for col in np.arange(X.shape[1]):\n",
    "#     print(feats[col], shapiro(X[:, col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "# stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "# manova_df = pd.DataFrame(\n",
    "#     data=stat_data,\n",
    "#     columns=feats + ['subscore'],\n",
    "# )\n",
    "# maov = MANOVA.from_formula(\n",
    "#     'nTaps + freq + mean_intraTapInt + coefVar_intraTapInt + IQR_jerkiness +'\n",
    "#     ' mean_raise_velocity + mean_tapRMSnrm ~ subscore ',\n",
    "#     # 'mean_jerkiness_smooth + IQR_jerkiness_smooth ~ subscore',\n",
    "#     data=manova_df,\n",
    "# )\n",
    "# print(maov.mv_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import kruskal\n",
    "# importlib.reload(pred_prep)\n",
    "\n",
    "# mask_scores = True\n",
    "\n",
    "# traces, feats = pred_prep.select_traces_and_feats(\n",
    "#     ftClass,\n",
    "#     center=center_incl,\n",
    "#     use_sel_fts=sel_feats,\n",
    "# )\n",
    "# X, y = pred_prep.create_X_y_vectors(\n",
    "#     ftClass,\n",
    "#     incl_traces=traces,\n",
    "#     incl_feats=feats,\n",
    "#     to_norm=False,\n",
    "# )\n",
    "# n_groups = 5\n",
    "# if mask_scores:\n",
    "#     # UPDRS 4 -> 3 merge\n",
    "#     mask = y == 4\n",
    "#     y[mask] = 3\n",
    "#     # UPDRS 0 -> 1 merge\n",
    "#     mask = y == 0\n",
    "#     y[mask] = 1\n",
    "\n",
    "#     n_groups = 3\n",
    "\n",
    "# stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "# stat_df = pd.DataFrame(\n",
    "#     data=stat_data,\n",
    "#     columns=feats + ['subscore'],\n",
    "# )\n",
    "\n",
    "# stat_fts = [\n",
    "#     'freq', 'coefVar_intraTapInt', 'mean_jerkiness', 'coefVar_jerkiness',\n",
    "#     'mean_tapRMSnrm', 'coefVar_tapRMSnrm', 'slope_tapRMSnrm'\n",
    "# ]\n",
    "# alpha = .05 / len(stat_fts)\n",
    "# for ft in stat_fts:\n",
    "#     tempft = stat_df[~np.isnan(stat_df[ft])]\n",
    "\n",
    "    \n",
    "#     if mask_scores:\n",
    "#         groups = [\n",
    "#             tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "#             for s in np.arange(1, n_groups + 1)\n",
    "#         ]\n",
    "#         krusk_stat, krusk_p = kruskal(\n",
    "#             groups[0], groups[1], groups[2], \n",
    "#         )\n",
    "#     else:\n",
    "#         groups = [\n",
    "#             tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "#             for s in np.arange(n_groups)\n",
    "#         ]\n",
    "#         krusk_stat, krusk_p = kruskal(\n",
    "#             groups[0], groups[1], groups[2], \n",
    "#             groups[3], groups[4]\n",
    "#         )\n",
    "#     print(f'\\n{ft}: \\n\\tGroup level sign. difference (Kruskal'\n",
    "#         f' Test): {krusk_p < alpha} (p = {np.round(krusk_p, 6)})\\n')\n",
    "#     for g in np.arange(n_groups - 1):\n",
    "\n",
    "#         mnwu_rho, mnwu_p = mannwhitneyu(groups[g], groups[g + 1])\n",
    "#         print(f'\\tupdrs {g} vs {g + 1} sign, (Mann-Whitney-U): '\n",
    "#             f'{mnwu_p < (alpha / (n_groups - 1))} (p = {np.round(mnwu_p, 6)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23a308fb4398211655e9950c8371f856de701ec09eac61c96054832e4a49057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
