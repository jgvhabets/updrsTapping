{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTap - UPDRS-Tapping Assessment - Predictions\n",
    "\n",
    "This notebooks investigates optimal hand- and fingertapping algorithms as part of the \n",
    "ReTune-Dyskinesia project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from array import array\n",
    "import datetime as dt\n",
    "import h5py\n",
    "from dataclasses import  dataclass, field\n",
    "from itertools import compress\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.12 (main, Jun  1 2022, 06:36:29) \n",
      "[Clang 12.0.0 ]\n",
      "pandas 1.4.3\n",
      "numpy 1.21.5\n",
      "sci-py 1.7.3\n",
      "sci-kit learn 1.1.1\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "\n",
    "\n",
    "## developed with:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1\n",
    "\n",
    "## Currently (own env) since 31.08.22\n",
    "# Python sys 3.9.12 (main, Jun  1 2022, 06:36:29) \n",
    "# [Clang 12.0.0 ]\n",
    "# pandas 1.4.3\n",
    "# numpy 1.21.5\n",
    "# sci-py 1.7.3\n",
    "# sci-kit learn 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_finding_10sec_blocks as run_find_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own data preprocessing functions\n",
    "import tap_load_data.updrsTapping_import as tap_import\n",
    "import tap_load_data.tapping_preprocess as tap_preproc\n",
    "import tap_load_data.tapping_find_blocks as find_blocks\n",
    "import tap_load_data.tapping_impact_finder as tap_impact\n",
    "import tap_load_data.tapping_time_detect as tap_times\n",
    "\n",
    "import tapping_run as tap_run\n",
    "\n",
    "# ft extraction\n",
    "import tap_extract_fts.tapping_featureset as tap_fts_set\n",
    "import tap_extract_fts.tapping_extract_features as tap_ft_extr\n",
    "import tap_extract_fts.tapping_feat_calc as ft_calc\n",
    "\n",
    "# own data exploration functions\n",
    "import tap_extract_fts.tapping_feat_boxplots as fts_boxplot\n",
    "\n",
    "# own helper functions\n",
    "from utils import utils_dataManagement, tmsi_poly5reader, utils_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRACT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['007_L_Off', '007_L_On', '007_R_Off', '007_R_On', '014_L_Off', '014_L_On', '014_R_Off', '014_R_On', '015_L_Off', '015_L_On', '015_R_Off', '015_R_On', '013_L_Off', '013_L_On', '013_R_Off', '013_R_On'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which sessions present\n",
    "\n",
    "block_acc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 007_L_Off\n",
      "No taps detected for 007_L_Off 2mA_block 1\n",
      "start 007_L_On\n",
      "start 007_R_Off\n",
      "No taps detected for 007_R_Off 05mA_block 1\n",
      "No taps detected for 007_R_Off 05mA_block 3\n",
      "No taps detected for 007_R_Off 1mA_block 1\n",
      "No taps detected for 007_R_Off 1mA_block 2\n",
      "No taps detected for 007_R_Off 1mA_block 3\n",
      "No taps detected for 007_R_Off 15mA_block 1\n",
      "No taps detected for 007_R_Off 15mA_block 3\n",
      "No taps detected for 007_R_Off 2mA_block 1\n",
      "No taps detected for 007_R_Off 2mA_block 2\n",
      "No taps detected for 007_R_Off 2mA_block 3\n",
      "start 007_R_On\n",
      "start 014_L_Off\n",
      "start 014_L_On\n",
      "start 014_R_Off\n",
      "start 014_R_On\n",
      "start 015_L_Off\n",
      "start 015_L_On\n",
      "start 015_R_Off\n",
      "start 015_R_On\n",
      "start 013_L_Off\n",
      "start 013_L_On\n",
      "start 013_R_Off\n",
      "start 013_R_On\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(tap_ft_extr)\n",
    "importlib.reload(tap_ft_extr)\n",
    "importlib.reload(tap_fts_set)\n",
    "\n",
    "\n",
    "# Read in priorly Block-Selection\n",
    "block_indx_json = os.path.join(\n",
    "    data_dir,\n",
    "    'prep_jsons',\n",
    "    'manual_block_selection_stimAmpRange.json'\n",
    ")\n",
    " \n",
    "with open(block_indx_json) as f:\n",
    "    block_indx = json.load(f, )\n",
    "\n",
    "\n",
    "FEATS = {}\n",
    "fs=250\n",
    "for run in block_acc.keys():\n",
    "    print(f'start {run}')\n",
    "\n",
    "    # to select subjects/runs to extract\n",
    "    splits = run.split('_')\n",
    "    # if splits[0] != '007': continue\n",
    "    # if splits[2] != 'Off': continue\n",
    "\n",
    "    for S, stim in enumerate(subscores[run].keys()):\n",
    "\n",
    "        for b, block in enumerate([1, 2, 3]):\n",
    "\n",
    "            tapscore = subscores[run][stim][b]\n",
    "            block_n = block_indx[run][stim][b]\n",
    "            tap_acc = block_acc[run][block_n]\n",
    "\n",
    "            tap_i, imp_i, acc_temp = tap_run.run_updrs_tapping(\n",
    "                acc_arr=tap_acc, fs=fs, already_preprocd=True,\n",
    "            )\n",
    "            \n",
    "            if len(tap_i) < 1:\n",
    "                # print(f'No taps detected for {run}_Stim{S}_block {block}')  # for OnOff\n",
    "                print(f'No taps detected for {run} {stim}_block {block}')  # for Range\n",
    "                # continue\n",
    "\n",
    "            FEATS[f'{run}_{stim}_b{block}'] = tap_ft_extr.tapFeatures(\n",
    "                triax_arr=acc_temp,\n",
    "                fs=fs,\n",
    "                impacts=imp_i,\n",
    "                tapDict=tap_i,  # result of continTap\n",
    "                updrsSubScore=tapscore,\n",
    "            )         \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clustering & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Candidate vetors based on descriptives and concept\n",
    "    - nTaps\n",
    "    - freq\n",
    "    - upVelo sum [std-dev + coefVar]\n",
    "    - impact RMS [coefVar + stddev]\n",
    "    - tapRMS and impactRMS [sum]\n",
    "    - \n",
    "- include per run (array tap-features): sum, mean, stddev, trend_slope\n",
    "\n",
    "- Cluster on UPDRS 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. ML-Vector Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tap_fts_set)\n",
    "\n",
    "FEATS['007_L_Off_1mA_b1'].impactRMS_svm\n",
    "\n",
    "tap_fts_set.amplitudeDecrement(\n",
    "    [\n",
    "        FEATS['007_L_Off_1mA_b1'].tapRMS_svm,\n",
    "        FEATS['007_L_Off_1mA_b1'].impactRMS_svm,\n",
    "        FEATS['007_L_Off_1mA_b1'].upVelo_svm\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['007_L_Off_0mA_b1',\n",
       " '007_L_Off_0mA_b2',\n",
       " '007_L_Off_0mA_b3',\n",
       " '007_L_Off_05mA_b1',\n",
       " '007_L_Off_05mA_b2',\n",
       " '007_L_Off_05mA_b3',\n",
       " '007_L_Off_1mA_b1',\n",
       " '007_L_Off_1mA_b2',\n",
       " '007_L_Off_1mA_b3',\n",
       " '007_L_Off_15mA_b1',\n",
       " '007_L_Off_15mA_b2',\n",
       " '007_L_Off_15mA_b3',\n",
       " '007_L_Off_2mA_b2',\n",
       " '007_L_Off_2mA_b3',\n",
       " '007_L_Off_25mA_b1',\n",
       " '007_L_Off_25mA_b2',\n",
       " '007_L_Off_25mA_b3',\n",
       " '007_L_On_0mA_b1',\n",
       " '007_L_On_0mA_b2',\n",
       " '007_L_On_0mA_b3',\n",
       " '007_L_On_05mA_b1',\n",
       " '007_L_On_05mA_b2',\n",
       " '007_L_On_05mA_b3',\n",
       " '007_L_On_1mA_b1',\n",
       " '007_L_On_1mA_b2',\n",
       " '007_L_On_1mA_b3',\n",
       " '007_L_On_15mA_b1',\n",
       " '007_L_On_15mA_b2',\n",
       " '007_L_On_15mA_b3',\n",
       " '007_L_On_2mA_b1',\n",
       " '007_L_On_2mA_b2',\n",
       " '007_L_On_2mA_b3',\n",
       " '007_L_On_25mA_b1',\n",
       " '007_L_On_25mA_b2',\n",
       " '007_L_On_25mA_b3',\n",
       " '007_L_On_3mA_b1',\n",
       " '007_L_On_3mA_b2',\n",
       " '007_L_On_3mA_b3',\n",
       " '007_R_Off_0mA_b1',\n",
       " '007_R_Off_0mA_b2',\n",
       " '007_R_Off_0mA_b3',\n",
       " '007_R_Off_05mA_b2',\n",
       " '007_R_Off_15mA_b2',\n",
       " '007_R_On_0mA_b1',\n",
       " '007_R_On_0mA_b2',\n",
       " '007_R_On_0mA_b3',\n",
       " '007_R_On_05mA_b1',\n",
       " '007_R_On_05mA_b2',\n",
       " '007_R_On_05mA_b3',\n",
       " '007_R_On_1mA_b1',\n",
       " '007_R_On_1mA_b2',\n",
       " '007_R_On_1mA_b3',\n",
       " '007_R_On_15mA_b1',\n",
       " '007_R_On_15mA_b2',\n",
       " '007_R_On_15mA_b3',\n",
       " '007_R_On_2mA_b1',\n",
       " '007_R_On_2mA_b2',\n",
       " '007_R_On_2mA_b3',\n",
       " '007_R_On_25mA_b1',\n",
       " '007_R_On_25mA_b2',\n",
       " '007_R_On_25mA_b3',\n",
       " '014_L_Off_0mA_b1',\n",
       " '014_L_Off_0mA_b2',\n",
       " '014_L_Off_0mA_b3',\n",
       " '014_L_Off_05mA_b1',\n",
       " '014_L_Off_05mA_b2',\n",
       " '014_L_Off_05mA_b3',\n",
       " '014_L_Off_1mA_b1',\n",
       " '014_L_Off_1mA_b2',\n",
       " '014_L_Off_1mA_b3',\n",
       " '014_L_Off_15mA_b1',\n",
       " '014_L_Off_15mA_b2',\n",
       " '014_L_Off_15mA_b3',\n",
       " '014_L_Off_2mA_b1',\n",
       " '014_L_Off_2mA_b2',\n",
       " '014_L_Off_2mA_b3',\n",
       " '014_L_Off_25mA_b1',\n",
       " '014_L_Off_25mA_b2',\n",
       " '014_L_Off_25mA_b3',\n",
       " '014_L_Off_3mA_b1',\n",
       " '014_L_Off_3mA_b2',\n",
       " '014_L_Off_3mA_b3',\n",
       " '014_L_On_0mA_b1',\n",
       " '014_L_On_0mA_b2',\n",
       " '014_L_On_0mA_b3',\n",
       " '014_L_On_05mA_b1',\n",
       " '014_L_On_05mA_b2',\n",
       " '014_L_On_05mA_b3',\n",
       " '014_L_On_1mA_b1',\n",
       " '014_L_On_1mA_b2',\n",
       " '014_L_On_1mA_b3',\n",
       " '014_L_On_15mA_b1',\n",
       " '014_L_On_15mA_b2',\n",
       " '014_L_On_15mA_b3',\n",
       " '014_L_On_2mA_b1',\n",
       " '014_L_On_2mA_b2',\n",
       " '014_L_On_2mA_b3',\n",
       " '014_L_On_25mA_b1',\n",
       " '014_L_On_25mA_b2',\n",
       " '014_L_On_25mA_b3',\n",
       " '014_L_On_3mA_b1',\n",
       " '014_L_On_3mA_b2',\n",
       " '014_L_On_3mA_b3',\n",
       " '014_R_Off_0mA_b1',\n",
       " '014_R_Off_0mA_b2',\n",
       " '014_R_Off_0mA_b3',\n",
       " '014_R_Off_05mA_b1',\n",
       " '014_R_Off_05mA_b2',\n",
       " '014_R_Off_05mA_b3',\n",
       " '014_R_Off_1mA_b1',\n",
       " '014_R_Off_1mA_b2',\n",
       " '014_R_Off_1mA_b3',\n",
       " '014_R_Off_15mA_b1',\n",
       " '014_R_Off_15mA_b2',\n",
       " '014_R_Off_15mA_b3',\n",
       " '014_R_Off_2mA_b1',\n",
       " '014_R_Off_2mA_b2',\n",
       " '014_R_Off_2mA_b3',\n",
       " '014_R_Off_25mA_b1',\n",
       " '014_R_Off_25mA_b2',\n",
       " '014_R_Off_25mA_b3',\n",
       " '014_R_Off_3mA_b1',\n",
       " '014_R_Off_3mA_b2',\n",
       " '014_R_Off_3mA_b3',\n",
       " '014_R_On_0mA_b1',\n",
       " '014_R_On_0mA_b2',\n",
       " '014_R_On_0mA_b3',\n",
       " '014_R_On_05mA_b1',\n",
       " '014_R_On_05mA_b2',\n",
       " '014_R_On_05mA_b3',\n",
       " '014_R_On_1mA_b1',\n",
       " '014_R_On_1mA_b2',\n",
       " '014_R_On_1mA_b3',\n",
       " '014_R_On_15mA_b1',\n",
       " '014_R_On_15mA_b2',\n",
       " '014_R_On_15mA_b3',\n",
       " '014_R_On_2mA_b1',\n",
       " '014_R_On_2mA_b2',\n",
       " '014_R_On_2mA_b3',\n",
       " '014_R_On_25mA_b1',\n",
       " '014_R_On_25mA_b2',\n",
       " '014_R_On_25mA_b3',\n",
       " '015_L_Off_0mA_b1',\n",
       " '015_L_Off_0mA_b2',\n",
       " '015_L_Off_0mA_b3',\n",
       " '015_L_Off_05mA_b1',\n",
       " '015_L_Off_05mA_b2',\n",
       " '015_L_Off_05mA_b3',\n",
       " '015_L_Off_1mA_b1',\n",
       " '015_L_Off_1mA_b2',\n",
       " '015_L_Off_1mA_b3',\n",
       " '015_L_Off_15mA_b1',\n",
       " '015_L_Off_15mA_b2',\n",
       " '015_L_Off_15mA_b3',\n",
       " '015_L_Off_2mA_b1',\n",
       " '015_L_Off_2mA_b2',\n",
       " '015_L_Off_2mA_b3',\n",
       " '015_L_Off_25mA_b1',\n",
       " '015_L_Off_25mA_b2',\n",
       " '015_L_Off_25mA_b3',\n",
       " '015_L_On_0mA_b1',\n",
       " '015_L_On_0mA_b2',\n",
       " '015_L_On_0mA_b3',\n",
       " '015_L_On_05mA_b1',\n",
       " '015_L_On_05mA_b2',\n",
       " '015_L_On_05mA_b3',\n",
       " '015_L_On_1mA_b1',\n",
       " '015_L_On_1mA_b2',\n",
       " '015_L_On_1mA_b3',\n",
       " '015_L_On_15mA_b1',\n",
       " '015_L_On_15mA_b2',\n",
       " '015_L_On_15mA_b3',\n",
       " '015_L_On_2mA_b1',\n",
       " '015_L_On_2mA_b2',\n",
       " '015_L_On_2mA_b3',\n",
       " '015_L_On_25mA_b1',\n",
       " '015_L_On_25mA_b2',\n",
       " '015_L_On_25mA_b3',\n",
       " '015_R_Off_0mA_b1',\n",
       " '015_R_Off_0mA_b2',\n",
       " '015_R_Off_0mA_b3',\n",
       " '015_R_Off_05mA_b1',\n",
       " '015_R_Off_05mA_b2',\n",
       " '015_R_Off_05mA_b3',\n",
       " '015_R_Off_1mA_b1',\n",
       " '015_R_Off_1mA_b2',\n",
       " '015_R_Off_1mA_b3',\n",
       " '015_R_Off_15mA_b1',\n",
       " '015_R_Off_15mA_b2',\n",
       " '015_R_Off_15mA_b3',\n",
       " '015_R_Off_2mA_b1',\n",
       " '015_R_Off_2mA_b2',\n",
       " '015_R_Off_2mA_b3',\n",
       " '015_R_Off_25mA_b1',\n",
       " '015_R_Off_25mA_b2',\n",
       " '015_R_Off_25mA_b3',\n",
       " '015_R_On_0mA_b1',\n",
       " '015_R_On_0mA_b2',\n",
       " '015_R_On_0mA_b3',\n",
       " '015_R_On_05mA_b1',\n",
       " '015_R_On_05mA_b2',\n",
       " '015_R_On_05mA_b3',\n",
       " '015_R_On_1mA_b1',\n",
       " '015_R_On_1mA_b2',\n",
       " '015_R_On_1mA_b3',\n",
       " '015_R_On_15mA_b1',\n",
       " '015_R_On_15mA_b2',\n",
       " '015_R_On_15mA_b3',\n",
       " '015_R_On_2mA_b1',\n",
       " '015_R_On_2mA_b2',\n",
       " '015_R_On_2mA_b3',\n",
       " '015_R_On_25mA_b1',\n",
       " '015_R_On_25mA_b2',\n",
       " '015_R_On_25mA_b3',\n",
       " '013_L_Off_0mA_b1',\n",
       " '013_L_Off_0mA_b2',\n",
       " '013_L_Off_0mA_b3',\n",
       " '013_L_Off_05mA_b1',\n",
       " '013_L_Off_05mA_b2',\n",
       " '013_L_Off_05mA_b3',\n",
       " '013_L_Off_1mA_b1',\n",
       " '013_L_Off_1mA_b2',\n",
       " '013_L_Off_1mA_b3',\n",
       " '013_L_Off_15mA_b1',\n",
       " '013_L_Off_15mA_b2',\n",
       " '013_L_Off_15mA_b3',\n",
       " '013_L_Off_2mA_b1',\n",
       " '013_L_Off_2mA_b2',\n",
       " '013_L_Off_2mA_b3',\n",
       " '013_L_Off_25mA_b1',\n",
       " '013_L_Off_25mA_b2',\n",
       " '013_L_Off_25mA_b3',\n",
       " '013_L_On_0mA_b1',\n",
       " '013_L_On_0mA_b2',\n",
       " '013_L_On_0mA_b3',\n",
       " '013_L_On_05mA_b1',\n",
       " '013_L_On_05mA_b2',\n",
       " '013_L_On_05mA_b3',\n",
       " '013_L_On_1mA_b1',\n",
       " '013_L_On_1mA_b2',\n",
       " '013_L_On_1mA_b3',\n",
       " '013_L_On_15mA_b1',\n",
       " '013_L_On_15mA_b2',\n",
       " '013_L_On_15mA_b3',\n",
       " '013_L_On_2mA_b1',\n",
       " '013_L_On_2mA_b2',\n",
       " '013_L_On_2mA_b3',\n",
       " '013_L_On_25mA_b1',\n",
       " '013_L_On_25mA_b2',\n",
       " '013_L_On_25mA_b3',\n",
       " '013_R_Off_0mA_b1',\n",
       " '013_R_Off_0mA_b2',\n",
       " '013_R_Off_0mA_b3',\n",
       " '013_R_Off_05mA_b1',\n",
       " '013_R_Off_05mA_b2',\n",
       " '013_R_Off_05mA_b3',\n",
       " '013_R_Off_1mA_b1',\n",
       " '013_R_Off_1mA_b2',\n",
       " '013_R_Off_1mA_b3',\n",
       " '013_R_Off_15mA_b1',\n",
       " '013_R_Off_15mA_b2',\n",
       " '013_R_Off_15mA_b3',\n",
       " '013_R_Off_2mA_b1',\n",
       " '013_R_Off_2mA_b2',\n",
       " '013_R_Off_2mA_b3',\n",
       " '013_R_Off_25mA_b1',\n",
       " '013_R_Off_25mA_b2',\n",
       " '013_R_Off_25mA_b3',\n",
       " '013_R_On_0mA_b1',\n",
       " '013_R_On_0mA_b2',\n",
       " '013_R_On_0mA_b3',\n",
       " '013_R_On_05mA_b1',\n",
       " '013_R_On_05mA_b2',\n",
       " '013_R_On_05mA_b3',\n",
       " '013_R_On_1mA_b1',\n",
       " '013_R_On_1mA_b2',\n",
       " '013_R_On_1mA_b3',\n",
       " '013_R_On_15mA_b1',\n",
       " '013_R_On_15mA_b2',\n",
       " '013_R_On_15mA_b3',\n",
       " '013_R_On_2mA_b1',\n",
       " '013_R_On_2mA_b2',\n",
       " '013_R_On_2mA_b3',\n",
       " '013_R_On_25mA_b1',\n",
       " '013_R_On_25mA_b2',\n",
       " '013_R_On_25mA_b3']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/var/folders/7d/4ptht2m910d1y872jrgp9cq40000gp/T/ipykernel_32352/1716791283.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Xdf.iloc[s][f'{ft_name}_{m}'] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/scipy/stats/_stats_mstats_common.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = ssxym / ssxm\n",
      "/Users/jeroenhabets/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/scipy/stats/_stats_mstats_common.py:184: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/Users/jeroenhabets/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/scipy/stats/_stats_mstats_common.py:187: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "artificial 0 added\n",
      "X array contains missing values:\n",
      " nTaps                         False\n",
      "freq                          False\n",
      "ampDecrement                   True\n",
      "tapRMS_svm_mean               False\n",
      "tapRMS_svm_coefVar            False\n",
      "tapRMS_svm_variance           False\n",
      "tapRMS_svm_sum                False\n",
      "tapRMS_svm_trend_slope        False\n",
      "upVelo_svm_mean               False\n",
      "upVelo_svm_coefVar            False\n",
      "upVelo_svm_variance           False\n",
      "upVelo_svm_sum                False\n",
      "upVelo_svm_trend_slope        False\n",
      "impactRMS_svm_mean            False\n",
      "impactRMS_svm_coefVar         False\n",
      "impactRMS_svm_variance        False\n",
      "impactRMS_svm_sum             False\n",
      "impactRMS_svm_trend_slope     False\n",
      "dirChange_taps_mean           False\n",
      "dirChange_taps_coefVar        False\n",
      "dirChange_taps_variance       False\n",
      "dirChange_taps_sum            False\n",
      "dirChange_taps_trend_slope    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb Cell 44'\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000037?line=92'>93</a>\u001b[0m \u001b[39m### assert np.sum(np.isnan(Xdf.values)) == 0\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000037?line=93'>94</a>\u001b[0m X \u001b[39m=\u001b[39m Xdf\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000037?line=95'>96</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39misnan(X)\u001b[39m.\u001b[39many() \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000037?line=96'>97</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mX array contains missing values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000037?line=97'>98</a>\u001b[0m     np\u001b[39m.\u001b[39misnan(Xdf)\u001b[39m.\u001b[39many()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000037?line=98'>99</a>\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "importlib.reload(ft_calc)\n",
    "\n",
    "ft_axis = 'svm'\n",
    "single_ft_names = [\n",
    "    'nTaps',\n",
    "    'freq',\n",
    "    'ampDecrement'\n",
    "]\n",
    "arr_ft_names = [\n",
    "    f'tapRMS_{ft_axis}',\n",
    "    f'upVelo_{ft_axis}',\n",
    "    f'impactRMS_{ft_axis}',\n",
    "    'dirChange_taps',\n",
    "]\n",
    "ft_aggr_to_add = [\n",
    "    'mean', 'coefVar', 'variance', 'sum', 'trend_slope'\n",
    "]\n",
    "\n",
    "\n",
    "valid_sel = [\n",
    "    len(FEATS[s].tapDict) > 0 for s in FEATS.keys()\n",
    "]\n",
    "valid_samples = list(compress(FEATS.keys(), valid_sel))\n",
    "n_samples = len(valid_samples)\n",
    "\n",
    "Xdf = pd.DataFrame(\n",
    "    data=np.zeros((\n",
    "        n_samples,\n",
    "        len(single_ft_names) + (\n",
    "            len(arr_ft_names) * len(ft_aggr_to_add)\n",
    "        )\n",
    "    )), columns=[single_ft_names + [\n",
    "        f'{f}_{m}' for f in arr_ft_names for m in ft_aggr_to_add\n",
    "    ]]\n",
    ")\n",
    "y = ft_calc.nan_array([Xdf.shape[0], 1])\n",
    "for s in range(Xdf.shape[0]):\n",
    "    y[s] = getattr(\n",
    "        FEATS[valid_samples[s]],\n",
    "        'updrsSubScore'\n",
    "    )\n",
    "\n",
    "for ft in single_ft_names:\n",
    "    for s, sam in enumerate(valid_samples):\n",
    "        try:\n",
    "            ft_value = getattr(FEATS[sam], ft)\n",
    "        except AttributeError:\n",
    "            print(sam)\n",
    "\n",
    "        Xdf.iloc[s][ft] = ft_value\n",
    "\n",
    "\n",
    "max_nTaps = np.max([FEATS[k].nTaps for k in valid_samples])\n",
    "\n",
    "arr_feats = ft_calc.nan_array([\n",
    "    len(arr_ft_names),\n",
    "    max_nTaps,\n",
    "    n_samples\n",
    "])\n",
    "\n",
    "for f, ft in enumerate(arr_ft_names):\n",
    "\n",
    "    for s, sam in enumerate(valid_samples):\n",
    "\n",
    "        ft_values = getattr(FEATS[sam], ft)\n",
    "        arr_feats[f, :len(ft_values), s] = ft_values\n",
    "\n",
    "# Normalise vector per array-feature over all samples\n",
    "for ft_row in range(len(arr_ft_names)):\n",
    "\n",
    "    vec_max = np.nanmax(arr_feats[ft_row, :, :])\n",
    "    arr_feats[ft_row, :, :] = arr_feats[ft_row, :, :] / vec_max\n",
    "\n",
    "# Normalise single feature over all samples\n",
    "for ft in single_ft_names:\n",
    "\n",
    "    fmax = np.max(Xdf[ft])\n",
    "    Xdf[ft] = Xdf[ft] / fmax\n",
    "\n",
    "# Aggregate array features\n",
    "for ft, ft_name in enumerate(arr_ft_names):\n",
    "\n",
    "    for m in ft_aggr_to_add:\n",
    "\n",
    "        for s in np.arange(Xdf.shape[0]):\n",
    "            \n",
    "            value = ft_calc.aggregate_arr_fts(\n",
    "                method=m, arr=arr_feats[ft, :, s]\n",
    "            )\n",
    "            \n",
    "            Xdf.iloc[s][f'{ft_name}_{m}'] = value\n",
    "\n",
    "### assert np.sum(np.isnan(Xdf.values)) == 0\n",
    "X = Xdf.values\n",
    "\n",
    "assert np.isnan(X).any() == False, print(\n",
    "    'X array contains missing values:\\n',\n",
    "    np.isnan(Xdf).any()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# DBSCAN\n",
    "# Laio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb Cell 46'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=8'>9</a>\u001b[0m \u001b[39m# X = pca.fit_transform(X)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=10'>11</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=11'>12</a>\u001b[0m     n_clusters\u001b[39m=\u001b[39mn_clusters,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=12'>13</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m27\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=13'>14</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=14'>15</a>\u001b[0m y_clust_labels \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39;49mfit_predict(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=15'>16</a>\u001b[0m centroids \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mcluster_centers_\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeroenhabets/Research/CHARITE/projects/tapping/code/updrsTapping_repo/updrsTapping_main_run.ipynb#ch0000040?line=17'>18</a>\u001b[0m y_cluster0 \u001b[39m=\u001b[39m y[y_clust_labels \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:996\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    974\u001b[0m     \u001b[39m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \n\u001b[1;32m    976\u001b[0m \u001b[39m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[39m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, sample_weight\u001b[39m=\u001b[39;49msample_weight)\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1365\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1340\u001b[0m     \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1341\u001b[0m \n\u001b[1;32m   1342\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1365\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1366\u001b[0m         X,\n\u001b[1;32m   1367\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1368\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   1369\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1370\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[1;32m   1371\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1372\u001b[0m     )\n\u001b[1;32m   1374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X)\n\u001b[1;32m   1375\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/updrsTapping/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "### Cluster Settings\n",
    "## test with full features and PCA1-2;\n",
    "## test first PCA cluster and full-fts classification within clusters\n",
    "n_clusters = 4\n",
    "\n",
    "\n",
    "X = Xdf.values\n",
    "pca = PCA(2)\n",
    "# X = pca.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    random_state=27\n",
    ")\n",
    "y_clust_labels = kmeans.fit_predict(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "y_cluster0 = y[y_clust_labels == 0]\n",
    "y_cluster1 = y[y_clust_labels == 1]\n",
    "\n",
    "score_cols = {\n",
    "    0: 'green',\n",
    "    1: 'blue',\n",
    "    2: 'orange',\n",
    "    3: 'red',\n",
    "    4: 'purple'\n",
    "}\n",
    "\n",
    "clMarkers = ['o', 'x', '*', '+', '^']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "s = 75\n",
    "for n, X_pca_row in enumerate(X):\n",
    "\n",
    "    score = int(y[n])\n",
    "    col = score_cols[score]\n",
    "\n",
    "    for clN in range(n_clusters):\n",
    "\n",
    "        if y_clust_labels[n] == clN:\n",
    "            \n",
    "            ax.scatter(\n",
    "                X[n, 0], X[n, 1],\n",
    "                label=f'Cluster-{clN}, Tap-Score {score}',\n",
    "                s=s, color=col, alpha=.8,\n",
    "                marker=clMarkers[clN],\n",
    "            )\n",
    "\n",
    "    # if y_clust_labels[n] == 0:\n",
    "    #     ax.scatter(\n",
    "    #         X[n, 0], X[n, 1],\n",
    "    #         label=f'Cluster-0, Tap-Score {score}',\n",
    "    #         # edgecolor=col, facecolor='w',\n",
    "    #         s=s, color=col, marker='*',\n",
    "    #     )\n",
    "    \n",
    "    # elif y_clust_labels[n] == 1:\n",
    "    #     ax.scatter(\n",
    "    #         X[n, 0], X[n, 1], marker='+',\n",
    "    #         label=f'Cluster-1, Tap-Score {score}',\n",
    "    #         color=col, s=s, alpha=.7,\n",
    "    #     )\n",
    "\n",
    "    # elif y_clust_labels[n] == 2:\n",
    "    #     ax.scatter(\n",
    "    #         X[n, 0], X[n, 1],\n",
    "    #         label=f'Cluster-2, Tap-Score {score}',\n",
    "    #         color=col, s=s, alpha=.7,\n",
    "    #     )\n",
    "\n",
    "for c in range(centroids.shape[0]):\n",
    "    ax.scatter(\n",
    "        centroids[c, 0], centroids[c, 1],\n",
    "        edgecolor='k', s=s + 50, fc='w',\n",
    "        label='Cluster centers'\n",
    "    )\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "ax.legend(\n",
    "    by_label.values(), by_label.keys(),\n",
    "    frameon=False, fontsize=16,\n",
    "    ncol=1,\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=[1.01, .95]\n",
    ")\n",
    "\n",
    "ax.set_xlabel('PCA-1', fontsize=18)\n",
    "ax.set_ylabel('PCA-2', fontsize=18)\n",
    "ax.set_title(\n",
    "    'kMeans Clustering 10-seconds of Finger Tapping',\n",
    "    fontsize=20\n",
    ")\n",
    "\n",
    "# plt.savefig(\n",
    "#     os.path.join(\n",
    "#         fig_dir,\n",
    "#         f'kMeans_{n_clusters}clusts_1AX_20220727'),\n",
    "#     dpi=150, facecolor='w',\n",
    "# )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.hist(labels0, color='purple')\n",
    "# plt.hist(labels1, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying UPDRS 0 - 1 - 2 - 3 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector, fold #0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7d/4ptht2m910d1y872jrgp9cq40000gp/T/ipykernel_10037/4282525040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# for own scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     ]:\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# CLassification Settings\n",
    "nFolds = 4\n",
    "\n",
    "# Shuffle order\n",
    "X = Xdf.values\n",
    "\n",
    "allData = np.hstack((X, y))\n",
    "X_shf = allData[:, :14]\n",
    "y_shf = allData[:, 14]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(allData)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds,)\n",
    "skf.get_n_splits(X_shf, y_shf)\n",
    "\n",
    "y_pred, y_true = {}, {}\n",
    "\n",
    "for F, (train_index, test_index) in enumerate(\n",
    "    skf.split(X, y)\n",
    "):\n",
    "    print(f'Linear Support Vector, fold #{F}')\n",
    "\n",
    "    X_train, X_test = X_shf[train_index], X_shf[test_index]\n",
    "    y_train, y_test = y_shf[train_index], y_shf[test_index]\n",
    "\n",
    "    clf = LinearSVC(penalty='l2', C=1.0,)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    print(clf.score(X=X_test, y=y_test))\n",
    "    # for own scoring\n",
    "    y_pred[F] = clf.predict(X=X_test)\n",
    "    y_true[F] = y_test\n",
    "    # print(multilabel_confusion_matrix(y_true[F], y_pred[F]))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Classifying (UPDRS 0 or 4 vs The Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of UPDRS subscore 0 versus thre rest\n",
      "\n",
      "Linear Support Vector, fold #0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7d/4ptht2m910d1y872jrgp9cq40000gp/T/ipykernel_10037/2107056001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {clf.score(X=X_test, y=y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# for own scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     ]:\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# CLassification Settings\n",
    "nFolds = 4\n",
    "score_to_predict = 0\n",
    "\n",
    "# Shuffle order\n",
    "X = Xdf.values\n",
    "y_bool = y == score_to_predict\n",
    "\n",
    "allData = np.hstack((X, y_bool))\n",
    "\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(allData)\n",
    "\n",
    "X_shf = allData[:, :14]\n",
    "y_shf = allData[:, 14]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds,)\n",
    "skf.get_n_splits(X_shf, y_shf)\n",
    "\n",
    "y_pred, y_true = {}, {}\n",
    "print(\n",
    "    'Classification of UPDRS subscore '\n",
    "    f'{score_to_predict} versus thre rest')\n",
    "for F, (train_index, test_index) in enumerate(\n",
    "    skf.split(X, y)\n",
    "):\n",
    "    print(f'\\nLinear Support Vector, fold #{F}')\n",
    "\n",
    "    X_train, X_test = X_shf[train_index], X_shf[test_index]\n",
    "    y_train, y_test = y_shf[train_index], y_shf[test_index]\n",
    "\n",
    "    clf = LinearSVC(penalty='l2', C=1.0,)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    print(f'Accuracy: {clf.score(X=X_test, y=y_test)}')\n",
    "    # for own scoring\n",
    "    y_pred[F] = clf.predict(X=X_test)\n",
    "    y_true[F] = y_test\n",
    "    print(classification_report(y_true[F], y_pred[F]))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('updrsTapping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0621c9b8aa60a8df3b6d56b3a59a35ac43d4d3d8937332cc4e1d97b67d9a738"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
