{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTap - UPDRS-Tapping Assessment - Predictions\n",
    "\n",
    "This notebooks investigates optimal hand- and fingertapping algorithms as part of the \n",
    "ReTune-Dyskinesia project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from array import array\n",
    "import datetime as dt\n",
    "from dataclasses import  dataclass, field\n",
    "from itertools import compress\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 1.4.4\n",
      "numpy 1.23.3\n",
      "sci-py 1.9.1\n",
      "sci-kit learn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "\n",
    "\n",
    "## developed with:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1\n",
    "\n",
    "## Currently (own env) since 31.08.22\n",
    "# Python sys 3.9.12 (main, Jun  1 2022, 06:36:29) \n",
    "# [Clang 12.0.0 ]\n",
    "# pandas 1.4.3\n",
    "# numpy 1.21.5\n",
    "# sci-py 1.7.3\n",
    "# sci-kit learn 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own functions\n",
    "from retap_utils import utils_dataManagement\n",
    "import retap_utils.get_datasplit as get_split\n",
    "\n",
    "import tap_predict.tap_pred_prepare as pred_prep\n",
    "import tap_plotting.retap_plot_clusters as plot_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split development and hold-out-test data sets\n",
    "\n",
    "- Development data is used to train and test the model using iterative cross-validation\n",
    "- Hold-out test data is NOT USED at all during cross-validation, and will be used to test the trained model as an external validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT CREATED CLASSES FROM FILES\n",
    "from tap_extract_fts.main_featExtractionClass import FeatureSet, singleTrace\n",
    "\n",
    "# define path with feature class\n",
    "deriv_path = os.path.join(utils_dataManagement.get_local_proj_dir(), 'data', 'derivatives')\n",
    "\n",
    "ftClass = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_20221214.P'))\n",
    "ftClass10 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_max10_20221214.P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sub', 'state', 'side', 'rep', 'center', 'filepath', 'tap_score', 'goal_Fs', 'to_extract_feats', 'max_n_taps_incl', 'acc_sig', 'fs', 'impact_idx', 'fts'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(ftClass10.BER019_M0S0_L_1).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ML-dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['triax_arr', 'fs', 'impacts', 'tap_lists', 'max_n_taps_incl', 'updrsSubScore', 'total_nTaps', 'freq', 'tap_durations', 'intraTapInt', 'tapRMS', 'tapRMSnrm', 'impactRMS', 'raise_velocity', 'jerkiness_taps', 'jerkiness_trace', 'mean_tapRMS', 'coefVar_tapRMS', 'IQR_tapRMS', 'decr_tapRMS', 'slope_tapRMS', 'mean_tapRMSnrm', 'coefVar_tapRMSnrm', 'IQR_tapRMSnrm', 'decr_tapRMSnrm', 'slope_tapRMSnrm', 'mean_impactRMS', 'coefVar_impactRMS', 'IQR_impactRMS', 'decr_impactRMS', 'slope_impactRMS', 'mean_raise_velocity', 'coefVar_raise_velocity', 'IQR_raise_velocity', 'decr_raise_velocity', 'slope_raise_velocity', 'mean_intraTapInt', 'coefVar_intraTapInt', 'IQR_intraTapInt', 'decr_intraTapInt', 'slope_intraTapInt', 'mean_jerkiness_taps', 'coefVar_jerkiness_taps', 'IQR_jerkiness_taps', 'decr_jerkiness_taps', 'slope_jerkiness_taps'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all present features\n",
    "vars(ftClass.BER055_M0S0_L_1.fts).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Including ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center='all',\n",
    "    use_sel_fts=True,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Ensemble method, start with clustering on intraTapInterval and overall tapping-frequency\n",
    "\n",
    "Create X1 with selected input features (mean and coef of variation of intra-tap-interval) and\n",
    "overall tapping frequency to find two clusters (y_clusters) dividing fast vs slow tappers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING DATA IN DEV AND HOLD-OUT\n",
      "Original score distribution: {0: 40, 1: 154, 2: 122, 3: 57, 4: 3}\n",
      "Original score %: {0: 10.6, 1: 41.0, 2: 32.4, 3: 15.2, 4: 0.8}\n",
      "Accepted Split: random state 63\n",
      "\n",
      "Resulting distributions in splitted data sets:\n",
      "\n",
      "\tdev data set (n = 285):\n",
      "score 0: # 32 (11 %)\n",
      "score 1: # 115 (40 %)\n",
      "score 2: # 94 (33 %)\n",
      "score 3: # 42 (15 %)\n",
      "score 4: # 2 (1 %)\n",
      "\thout data set (n = 91):\n",
      "score 0: # 8 (9 %)\n",
      "score 1: # 39 (43 %)\n",
      "score 2: # 28 (31 %)\n",
      "score 3: # 15 (16 %)\n",
      "score 4: # 1 (1 %)\n",
      "# of NaNs per feat: [0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean mean_intraTapInt (z-scored):\n",
      "\tcluster 0: -0.357289281961114\n",
      "\tcluster 1: 1.4546777908416781\n",
      "Fast tappers are clustered in cluster index 0\n",
      "Slow tappers are clustered in cluster index 1\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "importlib.reload(get_split)\n",
    "importlib.reload(plot_cluster)\n",
    "\n",
    "# set variables for pre-clustering\n",
    "n_clusters = 2\n",
    "traces_excl = [\n",
    "    'DUS006_M0S0_L_1',\n",
    "]\n",
    "ft_sel = [\n",
    "    'mean_intraTapInt',\n",
    "    'coefVar_intraTapInt',\n",
    "    'freq'\n",
    "]\n",
    "\n",
    "# include only dev dataset, exclude holdout data\n",
    "datasplit_subs = get_split.find_dev_holdout_split(\n",
    "    feats=ftClass10, )\n",
    "\n",
    "# create matrix to cluster with\n",
    "X_1, y, X1_ids = pred_prep.create_X_y_vectors(\n",
    "    ftClass=ftClass10,\n",
    "    incl_feats=ft_sel,\n",
    "    incl_traces=ftClass10.incl_traces,\n",
    "    excl_traces=traces_excl,\n",
    "    excl_subs=datasplit_subs['hout'],  # due to hold out data set\n",
    "    to_zscore=True,\n",
    "    return_ids=True,\n",
    ")\n",
    "\n",
    "## MASKING BCS TOO LOW NUMBERS\n",
    "# UPDRS 4 -> 3 merge (4: n=3)\n",
    "mask = y == 4\n",
    "y[mask] = 3\n",
    "\n",
    "# # UPDRS 0 -> 1 merge (0: n=40)\n",
    "# mask = y == 0\n",
    "# y[mask] = 1\n",
    "\n",
    "# create cluster labels\n",
    "y_clust, centr_clust, _ = plot_cluster.get_kMeans_clusters(\n",
    "    X=X_1,\n",
    "    n_clusters=n_clusters,\n",
    "    use_pca=True,\n",
    "    z_score=True,\n",
    ")\n",
    "\n",
    "# Define which cluster contains faster tappers\n",
    "cluster_mean_ITIs = []\n",
    "\n",
    "ft = 'mean_intraTapInt'\n",
    "print(f'Mean {ft} (z-scored):')\n",
    "for i_cls in np.unique(y_clust):\n",
    "\n",
    "    i_ft = np.where([f == ft for f in ft_sel])[0][0]\n",
    "    mean_iti_cluster = np.mean(X_1[y_clust == i_cls, i_ft])\n",
    "    cluster_mean_ITIs.append(mean_iti_cluster)\n",
    "\n",
    "    print(f'\\tcluster {i_cls}: {mean_iti_cluster}')\n",
    "\n",
    "fast_cluster_i = np.argmin(cluster_mean_ITIs)\n",
    "if fast_cluster_i == 0: slow_cluster_i = 1\n",
    "if fast_cluster_i == 1: slow_cluster_i = 0\n",
    "\n",
    "print(f'Fast tappers are clustered in cluster index {fast_cluster_i}')\n",
    "print(f'Slow tappers are clustered in cluster index {slow_cluster_i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make X_2 input Matrix with more features for score-prediction per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs per feat: [0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "incl_traces, ft_list = pred_prep.select_traces_and_feats(\n",
    "    ftClass10, use_sel_fts=True, excl_traces=traces_excl,\n",
    ")\n",
    "\n",
    "feats_for_2nd_pred = [\n",
    "    # 'freq',\n",
    "    'coefVar_intraTapInt',\n",
    "    # 'mean_intraTapInt',\n",
    "    # 'slope_intraTapInt',\n",
    "    'decr_intraTapInt',\n",
    "    'mean_tapRMS',\n",
    "    'coefVar_tapRMS',\n",
    "    # 'slope_tapRMS',\n",
    "    'decr_tapRMS',\n",
    "    'mean_raise_velocity',\n",
    "    'jerkiness_trace'\n",
    "]\n",
    "\n",
    "X_2, y, X2_ids = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=ftClass10.incl_traces,\n",
    "    incl_feats=feats_for_2nd_pred,\n",
    "    excl_traces=traces_excl,\n",
    "    excl_subs=datasplit_subs['hout'],  # due to hold out data set\n",
    "    to_norm=False,\n",
    "    to_zscore=True,\n",
    "    return_ids=True,\n",
    ")\n",
    "# Mask UPDRS 4 -> 3 merge (4: n=3)\n",
    "mask = y == 4\n",
    "y[mask] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 3) (284, 7) (284,) (284,) 7 (284,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    X_1.shape, X_2.shape, y.shape, y_clust.shape,\n",
    "    len(feats_for_2nd_pred), X2_ids.shape\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split input matrix X_2 in two generated clusters:\n",
    "- split X and y in two groups based on clusters\n",
    "- test default ML modeling on both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast X shape: (228, 7), Slow X shape: (56, 7)\n"
     ]
    }
   ],
   "source": [
    "X_2fast = X_2[y_clust == fast_cluster_i]\n",
    "y_2fast = y[y_clust == fast_cluster_i]\n",
    "fast_cls_ids = X2_ids[y_clust == fast_cluster_i]\n",
    "\n",
    "X_2slow = X_2[y_clust == slow_cluster_i]\n",
    "y_2slow = y[y_clust == slow_cluster_i]\n",
    "slow_cls_ids = X2_ids[y_clust == slow_cluster_i]\n",
    "\n",
    "print(f'Fast X shape: {X_2fast.shape}, Slow X shape: {X_2slow.shape}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise features in specific clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for boxplots of features per subscore, per cluster\n",
    "\n",
    "clst_X = X_2fast\n",
    "clst_y = y_2fast\n",
    "\n",
    "box_lists = {}\n",
    "for f in range(clst_X.shape[1]):\n",
    "    box_lists[f] = {}\n",
    "    for i in range(4): box_lists[f][i] = []\n",
    "\n",
    "\n",
    "for i in np.arange(clst_X.shape[0]):\n",
    "\n",
    "    score = clst_y[i]\n",
    "\n",
    "    for f in range(clst_X.shape[1]):\n",
    "\n",
    "        box_lists[f][int(score)].append(clst_X[i, f])\n",
    "\n",
    "# plot features within cluster, and decide on strategy\n",
    "# pm: use pre-knowledge about clusters\n",
    "# likelihood in faster cluster for 1-2 scores\n",
    "# use probabilities and adapt the threshold for acceptance\n",
    "# start finding border scores (e.g. 1 or 3)\n",
    "\n",
    "for i_f, ft in enumerate(feats_for_2nd_pred):\n",
    "\n",
    "    plot_lists = [box_lists[i_f][i] for i in range(4)]\n",
    "\n",
    "    plt.boxplot(plot_lists)\n",
    "    plt.title(ft)\n",
    "    plt.xticks(range(1, len(plot_lists) + 1), labels=['0', '1', '2', '3+4'])\n",
    "    plt.xlabel('UPDRS tap-score')\n",
    "    plt.ylabel('Z-score (a.u.)')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different prediction models for second step in Fast Cluster\n",
    "\n",
    "optimal thresholds (to prevent too large False Positive Values)\n",
    "#### predicting the best tappers (0-1)\n",
    "- .58 - .6 for LogReg\n",
    "- .6 for svm linear kernel\n",
    "- .6 for svm poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retap_utils.plot_helpers import remove_duplicate_legend\n",
    "from tap_predict import retap_cv_models as cv_models\n",
    "from tap_plotting import plot_cv_folds as plot_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, roc_curve,\n",
    "    accuracy_score, f1_score, precision_score,\n",
    "    recall_score, plot_roc_curve, plot_confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true,y_preds).ravel()\n",
    "# # add outcomes to dedicated lists\n",
    "# ['Accuracy'].append(accuracy_score(y_true,y_preds))\n",
    "# ['AUROC'].append(roc_auc_score(y_true, y_probas[1]))\n",
    "# ['F1_score'].append(f1_score(y_true,y_preds))\n",
    "# ['Precision'].append(precision_score(y_true, y_preds)) # precision/PPV\n",
    "# ['Recall'].append(recall_score(y_true, y_preds)) # sensitivity/recall/TPR\n",
    "# ['FPR'].append(fp / (fp+tn)) # false-positive, false-alarm rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_dev: (228, 7)\n",
      "predicting UPDRS score 1\n",
      "total y true: 127\n",
      "Chance level: 0.5570175438596491\n",
      "\n",
      "LogisticRegression(random_state=27)\n",
      "# of samples: train 171, test 57\n",
      "# true labels 31: chance is 0.543859649122807\n",
      "# of samples: train 171, test 57\n",
      "# true labels 32: chance is 0.5614035087719298\n",
      "# of samples: train 171, test 57\n",
      "# true labels 32: chance is 0.5614035087719298\n",
      "# of samples: train 171, test 57\n",
      "# true labels 32: chance is 0.5614035087719298\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "# CLassification Settings\n",
    "\n",
    "score_to_predict = 1\n",
    "clf_choice = 'logreg'\n",
    "nFolds = 4\n",
    "to_plot = False\n",
    "plot_thresholds = [.55, .58, .65]\n",
    "    \n",
    "X_cv = X_2fast.copy()\n",
    "y_cv = y_2fast.copy() <= score_to_predict\n",
    "ids_cv = fast_cls_ids.copy()\n",
    "\n",
    "roc_title = f'Identify UPDRS 0-1 ({clf_choice})'\n",
    "\n",
    "chance = sum(y_cv) / len(y_cv)\n",
    "\n",
    "print(f'shape of X_dev: {X_cv.shape}')\n",
    "print(f'predicting UPDRS score {score_to_predict}')\n",
    "print(f'total y true: {sum(y_cv)}')\n",
    "print(f'Chance level: {chance}')\n",
    "print()\n",
    "\n",
    "\n",
    "y_pred_dict, y_proba_dict, y_true_dict, og_pred_idx = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=X_cv, y_cv=y_cv,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    "    # sv_kernel='linear',\n",
    ")\n",
    "if to_plot: \n",
    "\n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "        incl_mean_ROC=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract best tappers (0-1 predicted) from fast-tappers and classify remaining part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_accept_thr = .58\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_decision = np.zeros((y_cv.shape))\n",
    "\n",
    "# loop over single probabilities in all folds\n",
    "for fold_n in y_proba_dict:\n",
    "    for i_proba, proba in enumerate(y_proba_dict[fold_n]):\n",
    "        # set correct index to True (1) of proba > acceptance threshold\n",
    "        if proba[1] > proba_accept_thr:\n",
    "            # find corresponding index in full cv data\n",
    "            og_idx = og_pred_idx[fold_n][i_proba]\n",
    "            clf_decision[og_idx] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BER019_M0S0_L_2', 'BER019_M0S0_L_1', 'BER019_M0S0_R_1',\n",
       "       'BER019_M0S0_R_2', 'BER019_M0S0_R_3', 'BER019_M0S1_L_1',\n",
       "       'BER019_M0S1_R_2', 'BER019_M0S1_R_3', 'BER019_M0S1_R_1',\n",
       "       'BER026_M0S0_L_2', 'BER026_M0S0_R_3', 'BER026_M0S0_R_1',\n",
       "       'BER026_M0S0_R_2', 'BER026_M0S1_L_3', 'BER026_M0S1_L_2',\n",
       "       'BER026_M0S1_L_1', 'BER026_M1S0_L_1', 'BER026_M1S0_L_3',\n",
       "       'BER026_M1S0_L_2', 'BER026_M1S0_R_3', 'BER026_M1S0_R_2',\n",
       "       'BER026_M1S0_R_1', 'BER026_M1S1_L_2', 'BER026_M1S1_L_3',\n",
       "       'BER026_M1S1_L_1', 'BER026_M1S1_R_3', 'BER026_M1S1_R_1',\n",
       "       'BER026_M1S1_R_2', 'BER033_M0S1_L_1', 'BER033_M0S1_L_2',\n",
       "       'BER033_M0S1_R_3', 'BER033_M0S1_R_1', 'BER028_M0S1_R_2',\n",
       "       'BER028_M1S0_L_1', 'BER028_M1S0_R_2', 'BER028_M1S0_R_3',\n",
       "       'BER028_M1S0_R_1', 'BER028_M1S1_R_3', 'BER028_M1S1_R_2',\n",
       "       'BER028_M1S1_R_1', 'BER024_M0S0_L_1', 'BER024_M0S0_L_2',\n",
       "       'BER024_M0S0_R_2', 'BER024_M0S0_R_3', 'BER024_M0S0_R_1',\n",
       "       'BER024_M0S1_L_1', 'BER024_M0S1_L_2', 'BER024_M0S1_L_3',\n",
       "       'BER024_M1S0_R_3', 'BER024_M1S0_R_2', 'BER024_M1S0_R_1',\n",
       "       'BER024_M1S1_L_1', 'BER024_M1S1_R_3', 'BER024_M1S1_R_1',\n",
       "       'BER024_M1S1_R_2', 'BER030_M0S0_R_2', 'BER049_M0S0_L_3',\n",
       "       'BER049_M0S0_L_2', 'BER049_M0S0_L_1', 'BER049_M0S0_R_2',\n",
       "       'BER049_M0S0_R_1', 'BER049_M0S0_R_3', 'BER049_M1S0_R_2',\n",
       "       'BER049_M1S0_R_1', 'BER049_M1S0_R_3', 'BER055_M0S0_L_2',\n",
       "       'BER055_M0S0_R_2', 'BER055_M1S0_R_1', 'BER021_M0S1_R_1',\n",
       "       'BER021_M0S1_R_3', 'BER021_M1S0_L_2', 'BER021_M1S0_R_3',\n",
       "       'BER021_M1S0_R_2', 'BER021_M1S0_R_1', 'BER021_M1S1_L_1',\n",
       "       'BER021_M1S1_R_1', 'BER021_M1S1_R_2', 'BER021_M1S1_R_3',\n",
       "       'BER051_M0S0_L_3', 'BER051_M0S0_L_1', 'BER051_M0S0_L_2',\n",
       "       'BER051_M1S0_L_2', 'BER051_M1S0_L_1', 'BER051_M1S0_L_3',\n",
       "       'BER051_M1S0_R_3', 'BER051_M1S0_R_1', 'BER051_M1S0_R_2',\n",
       "       'BER032_M0S0_L_3', 'BER032_M0S0_L_2', 'BER032_M0S0_L_1',\n",
       "       'BER032_M0S0_R_3', 'BER032_M0S0_R_1', 'BER032_M0S0_R_2',\n",
       "       'BER032_M1S0_L_1', 'BER032_M1S0_R_3', 'BER032_M1S0_R_1',\n",
       "       'BER032_M1S0_R_2', 'BER052_M0S0_R_3', 'BER052_M0S0_R_1',\n",
       "       'BER052_M0S0_R_2', 'BER052_M1S0_L_2', 'BER052_M1S0_L_1',\n",
       "       'BER052_M1S0_R_2', 'BER052_M1S0_R_3', 'BER025_M0S0_L_1',\n",
       "       'BER025_M0S0_L_2', 'BER025_M0S0_L_3', 'BER025_M0S1_L_1',\n",
       "       'BER025_M0S1_L_2', 'BER025_M0S1_L_3', 'BER025_M0S1_R_1',\n",
       "       'BER025_M0S1_R_3', 'DUS023_M1S1_L_1', 'DUS024_M0S1_L_1',\n",
       "       'DUS024_M1S1_L_1', 'DUS013_M0S0_L_1', 'DUS013_M0S1_L_1',\n",
       "       'DUS013_M1S1_L_1', 'DUS007_M0S0_L_1', 'DUS007_M1S1_L_1',\n",
       "       'DUS026_M0S1_L_1', 'DUS009_M1S1_L_1', 'DUS010_M1S0_L_1'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_cv[clf_decision.astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Clustering & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Candidate vetors based on descriptives and concept\n",
    "    - nTaps\n",
    "    - freq\n",
    "    - upVelo sum [std-dev + coefVar]\n",
    "    - impact RMS [coefVar + stddev]\n",
    "    - tapRMS and impactRMS [sum]\n",
    "    - \n",
    "- include per run (array tap-features): sum, mean, stddev, trend_slope\n",
    "\n",
    "- Cluster on UPDRS 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# try: K-shape (sklearn), Laio 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(plot_cluster)\n",
    "\n",
    "n_clusters=4\n",
    "center_incl = 'all'\n",
    "sel_feats = True\n",
    "\n",
    "\n",
    "### VISUALISE AGAINST SUBS !! AND CONDITIONS\n",
    "\n",
    "\n",
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center=center_incl,\n",
    "    use_sel_fts=sel_feats,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "\n",
    "figname = (\n",
    "    f'retap_{n_clusters}clusters_'\n",
    "    f'{center_incl}'\n",
    ")\n",
    "if sel_feats: figname += '_selFeats'\n",
    "else: figname += '_allFeats'\n",
    "\n",
    "plot_cluster.plot_cluster_kMeans(\n",
    "    X=X, y=y,\n",
    "    n_clusters=n_clusters,\n",
    "    use_pca=True,\n",
    "    random_state=27,\n",
    "    figsave_name=figname,\n",
    "    figsave_dir=os.path.join(\n",
    "        utils_dataManagement.find_onedrive_path('figures'),\n",
    "        'clustering',\n",
    "    ),\n",
    "    show=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANOVA\n",
    "\n",
    "- normality assumption violated (Shapiro test highly significant)\n",
    "- for every a priori selected feature: present difference between sub-score-groups is a Kruskal-Wallis test (non-parametric One-Way ANOVA alternative)\n",
    "- differences between two sub groups within a feature is a non-parametric test of two groups of quantitative values (likely varying lengths): Mann-Whitney-U\n",
    "- in total: correct alpha for number of repeated measures on specific level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "for col in np.arange(X.shape[1]):\n",
    "    print(feats[col], shapiro(X[:, col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Multivariate linear model\n",
      "==============================================================\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "       Intercept        Value  Num DF  Den DF  F Value  Pr > F\n",
      "--------------------------------------------------------------\n",
      "          Wilks' lambda 0.1239 7.0000 365.0000 368.6918 0.0000\n",
      "         Pillai's trace 0.8761 7.0000 365.0000 368.6918 0.0000\n",
      " Hotelling-Lawley trace 7.0708 7.0000 365.0000 368.6918 0.0000\n",
      "    Roy's greatest root 7.0708 7.0000 365.0000 368.6918 0.0000\n",
      "--------------------------------------------------------------\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "         subscore        Value  Num DF  Den DF  F Value Pr > F\n",
      "--------------------------------------------------------------\n",
      "           Wilks' lambda 0.7803 7.0000 365.0000 14.6821 0.0000\n",
      "          Pillai's trace 0.2197 7.0000 365.0000 14.6821 0.0000\n",
      "  Hotelling-Lawley trace 0.2816 7.0000 365.0000 14.6821 0.0000\n",
      "     Roy's greatest root 0.2816 7.0000 365.0000 14.6821 0.0000\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "manova_df = pd.DataFrame(\n",
    "    data=stat_data,\n",
    "    columns=feats + ['subscore'],\n",
    ")\n",
    "maov = MANOVA.from_formula(\n",
    "    'nTaps + freq + mean_intraTapInt + coefVar_intraTapInt + IQR_jerkiness +'\n",
    "    ' mean_raise_velocity + mean_tapRMSnrm ~ subscore ',\n",
    "    # 'mean_jerkiness_smooth + IQR_jerkiness_smooth ~ subscore',\n",
    "    data=manova_df,\n",
    ")\n",
    "print(maov.mv_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "freq: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 3.8e-05)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.485159)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 0.00025)\n",
      "\n",
      "coefVar_intraTapInt: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 0.0)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.084536)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 4.8e-05)\n",
      "\n",
      "mean_jerkiness: \n",
      "\tGroup level sign. difference (Kruskal Test): False (p = 0.331604)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.375883)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): False (p = 0.140139)\n",
      "\n",
      "coefVar_jerkiness: \n",
      "\tGroup level sign. difference (Kruskal Test): False (p = 0.719329)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.507749)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): False (p = 0.490786)\n",
      "\n",
      "mean_tapRMSnrm: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 3e-06)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.017736)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 0.00162)\n",
      "\n",
      "coefVar_tapRMSnrm: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 3e-06)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.417794)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 4e-06)\n",
      "\n",
      "slope_tapRMSnrm: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 1e-06)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.012758)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 0.000827)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "importlib.reload(pred_prep)\n",
    "\n",
    "mask_scores = True\n",
    "\n",
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center=center_incl,\n",
    "    use_sel_fts=sel_feats,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "n_groups = 5\n",
    "if mask_scores:\n",
    "    # UPDRS 4 -> 3 merge\n",
    "    mask = y == 4\n",
    "    y[mask] = 3\n",
    "    # UPDRS 0 -> 1 merge\n",
    "    mask = y == 0\n",
    "    y[mask] = 1\n",
    "\n",
    "    n_groups = 3\n",
    "\n",
    "stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "stat_df = pd.DataFrame(\n",
    "    data=stat_data,\n",
    "    columns=feats + ['subscore'],\n",
    ")\n",
    "\n",
    "stat_fts = [\n",
    "    'freq', 'coefVar_intraTapInt', 'mean_jerkiness', 'coefVar_jerkiness',\n",
    "    'mean_tapRMSnrm', 'coefVar_tapRMSnrm', 'slope_tapRMSnrm'\n",
    "]\n",
    "alpha = .05 / len(stat_fts)\n",
    "for ft in stat_fts:\n",
    "    tempft = stat_df[~np.isnan(stat_df[ft])]\n",
    "\n",
    "    \n",
    "    if mask_scores:\n",
    "        groups = [\n",
    "            tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "            for s in np.arange(1, n_groups + 1)\n",
    "        ]\n",
    "        krusk_stat, krusk_p = kruskal(\n",
    "            groups[0], groups[1], groups[2], \n",
    "        )\n",
    "    else:\n",
    "        groups = [\n",
    "            tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "            for s in np.arange(n_groups)\n",
    "        ]\n",
    "        krusk_stat, krusk_p = kruskal(\n",
    "            groups[0], groups[1], groups[2], \n",
    "            groups[3], groups[4]\n",
    "        )\n",
    "    print(f'\\n{ft}: \\n\\tGroup level sign. difference (Kruskal'\n",
    "        f' Test): {krusk_p < alpha} (p = {np.round(krusk_p, 6)})\\n')\n",
    "    for g in np.arange(n_groups - 1):\n",
    "\n",
    "        mnwu_rho, mnwu_p = mannwhitneyu(groups[g], groups[g + 1])\n",
    "        print(f'\\tupdrs {g} vs {g + 1} sign, (Mann-Whitney-U): '\n",
    "            f'{mnwu_p < (alpha / (n_groups - 1))} (p = {np.round(mnwu_p, 6)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "\n",
    "# UPDRS 4 -> 3 merge\n",
    "mask = y == 4\n",
    "y[mask] = 3\n",
    "# UPDRS 0 -> 1 merge\n",
    "mask = y == 0\n",
    "y[mask] = 1\n",
    "### 3c. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying UPDRS 0 - 1 - 2 - 3 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 12)\n",
      "0.19776827012025905\n",
      "[0.17021277 0.14893617 0.21276596 0.21276596 0.19148936 0.15217391\n",
      " 0.13043478 0.2173913  0.14893617 0.08510638 0.17021277 0.23404255\n",
      " 0.17021277 0.30434783 0.23913043 0.2826087  0.14893617 0.25531915\n",
      " 0.12765957 0.17021277 0.19148936 0.17391304 0.2173913  0.10869565\n",
      " 0.27659574 0.12765957 0.21276596 0.17021277 0.29787234 0.26086957\n",
      " 0.06521739 0.19565217 0.25531915 0.19148936 0.29787234 0.23404255\n",
      " 0.19148936 0.17391304 0.17391304 0.13043478 0.17021277 0.23404255\n",
      " 0.23404255 0.29787234 0.19148936 0.13043478 0.19565217 0.26086957\n",
      " 0.14893617 0.21276596 0.31914894 0.25531915 0.10638298 0.15217391\n",
      " 0.17391304 0.23913043 0.21276596 0.21276596 0.14893617 0.25531915\n",
      " 0.27659574 0.15217391 0.17391304 0.13043478 0.21276596 0.19148936\n",
      " 0.29787234 0.19148936 0.19148936 0.08695652 0.23913043 0.26086957\n",
      " 0.19148936 0.23404255 0.27659574 0.14893617 0.10638298 0.19565217\n",
      " 0.2173913  0.17391304]\n"
     ]
    }
   ],
   "source": [
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center='all',\n",
    "    use_sel_fts=True,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "print(X.shape)\n",
    "\n",
    "# use random outcome labels (equal distribution over scores)\n",
    "random_y = np.random.randint(0, 5, size=X.shape[0])\n",
    "y = random_y\n",
    "# use shuffled outcome labels (same distribution)\n",
    "np.random.seed(27)\n",
    "# np.random.shuffle(y)\n",
    "\n",
    "# UPDRS 4 -> 3 merge\n",
    "# mask = y == 4\n",
    "# y[mask] = 3\n",
    "# # UPDRS 0 -> 1 merge\n",
    "# mask = y == 0\n",
    "# y[mask] = 1\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X, y)\n",
    "\n",
    "#Define method to evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=10, random_state=1)\n",
    "\n",
    "#evaluate model\n",
    "scores = cross_val_score(lda, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores)) \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean Accuracy: 0.534068278805121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLassification Settings\n",
    "\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "# print(f'INCLUDED FEATURE SPACE: {X.shape}')\n",
    "\n",
    "nFolds = 10\n",
    "\n",
    "# UPDRS 4 -> 3 merge\n",
    "mask = y == 4\n",
    "y[mask] = 3\n",
    "# UPDRS 0 -> 1 merge\n",
    "mask = y == 0\n",
    "y[mask] = 1\n",
    "\n",
    "\n",
    "# Shuffle order\n",
    "# allData = np.hstack((X, y))\n",
    "# X_shf = allData[:, :14]\n",
    "# y_shf = allData[:, 14]\n",
    "\n",
    "# np.random.shuffle(allData)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds,)\n",
    "skf.get_n_splits(X, y)\n",
    "# clf = LinearSVC(\n",
    "#         penalty='l2',\n",
    "#     C=1.0,\n",
    "#     multi_class='ovr',\n",
    "#     max_iter=10000,\n",
    "# )\n",
    "clf = LogisticRegression(\n",
    "    random_state=0, \n",
    "    solver='liblinear',\n",
    "    multi_class='ovr',\n",
    ")\n",
    "\n",
    "shuffled_accs = []\n",
    "np.random.seed(27)\n",
    "# for r_state in np.random.randint(100, size=1000):\n",
    "\n",
    "    # np.random.seed(r_state)\n",
    "    # # y_shuffled = y.copy()\n",
    "    # # np.random.shuffle(y_shuffled)\n",
    "    # np.random.shuffle(y)\n",
    "\n",
    "y_pred, y_true = {}, {}\n",
    "all_accs = []\n",
    "for F, (train_index, test_index) in enumerate(\n",
    "    skf.split(X, y)\n",
    "):\n",
    "    # print(f'\\nLinear Support Vector, fold #{F}')\n",
    "    # print(f'\\nLogistic Regression, fold #{F}')\n",
    "    # print(\n",
    "    #     f'\\tn train: {train_index.shape}, '\n",
    "    #     f'n test: {test_index.shape}')\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # print('\\tcount for y-labels in test set\\n',\n",
    "    #     np.array(np.unique(y_test, return_counts=True)).T)\n",
    "    \n",
    "    clf = clf\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    acc = clf.score(X=X_test, y=y_test)\n",
    "    # print(\n",
    "    #     f'accuracy for Fold {F}: {acc}')\n",
    "    all_accs.append(acc)\n",
    "    \n",
    "    # save predictions for posthoc analysis and conf matrix\n",
    "    y_pred[F] = clf.predict(X=X_test)\n",
    "    y_true[F] = y_test\n",
    "    # print(multilabel_confusion_matrix(y_true[F], y_pred[F]))\n",
    "\n",
    "        \n",
    "print(f'Overall mean Accuracy: {np.mean(all_accs)}\\n')\n",
    "    # shuffled_accs.append(np.mean(all_accs))\n",
    "\n",
    "# print('grand mean', np.mean(shuffled_accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean Accuracy: 0.4047700754975978\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall mean Accuracy: {np.mean(all_accs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Classifying (UPDRS 0 or 4 vs The Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of UPDRS subscore 0 versus thre rest\n",
      "\n",
      "Linear Support Vector, fold #0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7d/4ptht2m910d1y872jrgp9cq40000gp/T/ipykernel_10037/2107056001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {clf.score(X=X_test, y=y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# for own scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     ]:\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# CLassification Settings\n",
    "nFolds = 4\n",
    "score_to_predict = 0\n",
    "\n",
    "# Shuffle order\n",
    "X = Xdf.values\n",
    "y_bool = y == score_to_predict\n",
    "\n",
    "allData = np.hstack((X, y_bool))\n",
    "\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(allData)\n",
    "\n",
    "X_shf = allData[:, :14]\n",
    "y_shf = allData[:, 14]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds,)\n",
    "skf.get_n_splits(X_shf, y_shf)\n",
    "\n",
    "y_pred, y_true = {}, {}\n",
    "print(\n",
    "    'Classification of UPDRS subscore '\n",
    "    f'{score_to_predict} versus thre rest')\n",
    "for F, (train_index, test_index) in enumerate(\n",
    "    skf.split(X, y)\n",
    "):\n",
    "    print(f'\\nLinear Support Vector, fold #{F}')\n",
    "\n",
    "    X_train, X_test = X_shf[train_index], X_shf[test_index]\n",
    "    y_train, y_test = y_shf[train_index], y_shf[test_index]\n",
    "\n",
    "    clf = LinearSVC(penalty='l2', C=1.0,)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    print(f'Accuracy: {clf.score(X=X_test, y=y_test)}')\n",
    "    # for own scoring\n",
    "    y_pred[F] = clf.predict(X=X_test)\n",
    "    y_true[F] = y_test\n",
    "    print(classification_report(y_true[F], y_pred[F]))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23a308fb4398211655e9950c8371f856de701ec09eac61c96054832e4a49057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
