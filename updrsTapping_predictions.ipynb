{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTap - UPDRS-Tapping Assessment - Predictions\n",
    "\n",
    "This notebooks investigates optimal hand- and fingertapping algorithms as part of the \n",
    "ReTune-Dyskinesia project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from array import array\n",
    "import datetime as dt\n",
    "from dataclasses import  dataclass, field\n",
    "from itertools import compress\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 1.4.4\n",
      "numpy 1.23.3\n",
      "sci-py 1.9.1\n",
      "sci-kit learn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "\n",
    "\n",
    "## developed with:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1\n",
    "\n",
    "## Currently (own env) since 31.08.22\n",
    "# Python sys 3.9.12 (main, Jun  1 2022, 06:36:29) \n",
    "# [Clang 12.0.0 ]\n",
    "# pandas 1.4.3\n",
    "# numpy 1.21.5\n",
    "# sci-py 1.7.3\n",
    "# sci-kit learn 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own functions\n",
    "from retap_utils import utils_dataManagement\n",
    "import retap_utils.get_datasplit as get_split\n",
    "\n",
    "import tap_predict.tap_pred_prepare as pred_prep\n",
    "import tap_predict.tap_pred_help as pred_help\n",
    "import tap_plotting.retap_plot_clusters as plot_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split development and hold-out-test data sets\n",
    "\n",
    "- Development data is used to train and test the model using iterative cross-validation\n",
    "- Hold-out test data is NOT USED at all during cross-validation, and will be used to test the trained model as an external validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT CREATED CLASSES FROM FILES\n",
    "\n",
    "# import of feature classes is mandatory to use pickle below\n",
    "from tap_extract_fts.main_featExtractionClass import FeatureSet, singleTrace\n",
    "\n",
    "# define path with feature class\n",
    "deriv_path = os.path.join(utils_dataManagement.get_local_proj_dir(), 'data', 'derivatives')\n",
    "\n",
    "# ftClass = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_20221214.P'))\n",
    "# ftClass10 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_max10_20221214.P'))\n",
    "\n",
    "newFts = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_20230301.P'))\n",
    "newFts10 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_max10_20230228.P'))\n",
    "newFts15 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_max15_20230228.P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 18 included SUBS for BER\n",
      "# 311 included TRACES for BER\n",
      "# 19 included SUBS for DUS\n",
      "# 65 included TRACES for DUS\n"
     ]
    }
   ],
   "source": [
    "subs = []\n",
    "for t in newFts.incl_traces:\n",
    "    subs.append(getattr(newFts, t).sub)\n",
    "\n",
    "unique_subs = list(set(subs))\n",
    "\n",
    "for cen in ['BER', 'DUS']:\n",
    "    n = sum([cen in t for t in unique_subs])\n",
    "    print(f'# {n} included SUBS for {cen}')\n",
    "    n = sum([cen in t for t in newFts.incl_traces])\n",
    "    print(f'# {n} included TRACES for {cen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER023_M1S0_R_2\n"
     ]
    }
   ],
   "source": [
    "for t in newFts.incl_traces:\n",
    "    if getattr(newFts, t).tap_score == 4:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ML-dataset Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble method: 1) score too few taps as 3, 2) cluster on tapping-frequency features, 3) K-Fold cv of Classification model\n",
    "\n",
    "Create X1 with selected input features (mean and coef of variation of intra-tap-interval) and\n",
    "overall tapping frequency to find two clusters (y_clusters) dividing fast vs slow tappers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for classification method\n",
    "MAX_TAPS_PER_TRACE = None\n",
    "USE_FT_CLASS = newFts\n",
    "DATASPLIT = 'CROSSVAL'  # should be CROSSVAL or HOLDOUT\n",
    "N_RANDOM_SPLIT = 41  # 01.03.23\n",
    "\n",
    "SUBS_EXCL = ['BER028']  # too many missing acc-data\n",
    "TRACES_EXCL = ['DUS006_M0S0_L_1', 'BER023_M1S0_R_2']  # no score/video\n",
    "\n",
    "SCORE_FEW_TAPS_3 = True\n",
    "CUTOFF_TAPS_3 = 9\n",
    "\n",
    "CLUSTER_ON_FREQ = False\n",
    "N_CLUSTERS_FEQ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK FOR MISSING ACC DATA IN TRACES\n",
    "# for t in newFts.incl_traces:\n",
    "\n",
    "#     sig = getattr(newFts, t).acc_sig\n",
    "#     nan_ratio = sum(np.isnan(sig).any(axis=0)) / sig.shape[1]\n",
    "\n",
    "#     if nan_ratio > 0: print(t, nan_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excl sub: BER028, led to 24 excl traces\n"
     ]
    }
   ],
   "source": [
    "excl_sub = 'BER028'\n",
    "excl_sub_traces = [t for t in newFts.incl_traces if t.startswith(excl_sub)]\n",
    "print(f'excl sub: {excl_sub}, led to {len(excl_sub_traces)} excl traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING DATA IN DEV AND HOLD-OUT\n",
      "Original score distribution: {0: 40, 1: 149, 2: 106, 3: 55}\n",
      "Original score %: {0: 11.4, 1: 42.6, 2: 30.3, 3: 15.7}\n",
      "Accepted Split: random state 41\n",
      "\n",
      "Resulting distributions in splitted data sets:\n",
      "\n",
      "\tdev data set (n = 263):\n",
      "score 0: # 30 (11 %)\n",
      "score 1: # 109 (41 %)\n",
      "score 2: # 81 (31 %)\n",
      "score 3: # 43 (16 %)\n",
      "score 4: # 0 (0 %)\n",
      "\thout data set (n = 89):\n",
      "score 0: # 10 (11 %)\n",
      "score 1: # 40 (45 %)\n",
      "score 2: # 26 (29 %)\n",
      "score 3: # 12 (13 %)\n",
      "score 4: # 1 (1 %)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(get_split)\n",
    "\n",
    "### GET DATA SPLIT CROSS-VAL OR HOLD-OUT\n",
    "# get dict with dev and hold-out datasets\n",
    "datasplit_subs = get_split.find_dev_holdout_split(\n",
    "    feats=USE_FT_CLASS,\n",
    "    subs_excl=SUBS_EXCL,\n",
    "    traces_excl=TRACES_EXCL,\n",
    "    # choose_random_split=None\n",
    ")\n",
    "\n",
    "if DATASPLIT == 'CROSSVAL': SUBS_EXCL.extend(datasplit_subs['hout'])\n",
    "elif DATASPLIT == 'HOLDOUT': SUBS_EXCL.extend(datasplit_subs['dev'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform AFTER data split\n",
    "if SCORE_FEW_TAPS_3:\n",
    "    (\n",
    "        classf_taps_3,\n",
    "        y_pred_fewTaps,\n",
    "        y_true_fewTaps\n",
    "    ) = pred_help.classify_based_on_nTaps(\n",
    "        max_n_taps=CUTOFF_TAPS_3,\n",
    "        ftClass=USE_FT_CLASS,\n",
    "        # in_cv=True\n",
    "    )\n",
    "    # select traces from subs present in current datasplit\n",
    "    if DATASPLIT == 'CROSSVAL':\n",
    "        datasplit_sel = [\n",
    "            np.array([t.startswith(s) for s in datasplit_subs['dev']]).any()\n",
    "            for t in classf_taps_3\n",
    "        ]\n",
    "    elif DATASPLIT == 'HOLDOUT':\n",
    "        datasplit_sel = [\n",
    "            np.array([t.startswith(s) for s in datasplit_subs['hout']]).any()\n",
    "            for t in classf_taps_3\n",
    "        ]\n",
    "    \n",
    "    TRACES_EXCL.extend(list(compress(classf_taps_3, datasplit_sel)))\n",
    "    y_pred_fewTaps = list(compress(y_pred_fewTaps, datasplit_sel))\n",
    "    y_true_fewTaps = list(compress(y_true_fewTaps, datasplit_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSVAL\n",
      "Traces with not enough taps detected: ['BER025_M0S0_R_1', 'BER025_M1S0_R_3', 'BER033_M0S0_R_2', 'DUS006_M0S0_L_1', 'DUS026_M1S0_L_1', 'DUS022_M0S0_L_1']\n",
      "corresponding true values: [3, 3, 3, 2, 1, 3]\n",
      "corresponding predictions: [3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "fewTaps_tracenames = list(compress(classf_taps_3, datasplit_sel))\n",
    "print(DATASPLIT)\n",
    "print(f'Traces with not enough taps detected: '\n",
    "      f'{fewTaps_tracenames}')\n",
    "print(f'corresponding true values: {y_true_fewTaps}')\n",
    "print(f'corresponding predictions: {y_pred_fewTaps}')\n",
    "\n",
    "# for t in fewTaps_tracenames:\n",
    "#     print()\n",
    "#     print(t, getattr(newFts, t).tap_score)\n",
    "#     t = getattr(newFts15, t)\n",
    "#     for ft in ['tapRMS', 'raise_velocity', 'impactRMS']:\n",
    "#         print(ft, sum(getattr(t.fts, ft)), np.mean(getattr(t.fts, ft)),\n",
    "#               stats.variation(getattr(t.fts, ft)))\n",
    "#     # plt.plot(t.acc_sig.T)\n",
    "#     # plt.show()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT\n",
      "Traces with not enough taps detected: ['BER023_M0S0_R_3', 'BER023_M0S0_R_2', 'BER023_M1S0_L_3', 'BER023_M1S0_L_2', 'BER023_M1S0_R_1', 'BER023_M1S0_R_2', 'BER023_M1S0_R_3', 'DUS017_M1S0_L_1', 'DUS017_M1S1_L_1']\n",
      "corresponding true values: [3, 3, 3, 3, 3, 3, 3, 1, 1]\n",
      "corresponding predictions: [3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(DATASPLIT)\n",
    "print(f'Traces with not enough taps detected: '\n",
    "      f'{list(compress(classf_taps_3, datasplit_sel))}')\n",
    "print(f'corresponding true values: {y_true_fewTaps}')\n",
    "print(f'corresponding predictions: {y_pred_fewTaps}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make X input Matrix with more features for score-prediction (per Cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 14)\n",
      "# of NaNs per feat: [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "to_mask_4 = True\n",
    "to_mask_0 = False\n",
    "to_zscore = True\n",
    "to_norm = False\n",
    "\n",
    "CLASS_FEATS = [\n",
    "    'trace_RMSn',\n",
    "    'trace_entropy',\n",
    "    'jerkiness_trace',\n",
    "\n",
    "    'coefVar_intraTapInt',\n",
    "    'slope_intraTapInt',\n",
    "    'mean_tapRMS',\n",
    "    'coefVar_tapRMS',\n",
    "    'mean_impactRMS',\n",
    "    'coefVar_impactRMS',\n",
    "    'slope_impactRMS',\n",
    "    'mean_raise_velocity',\n",
    "    'coefVar_raise_velocity',\n",
    "    'coefVar_tap_entropy',\n",
    "    'slope_tap_entropy',\n",
    "\n",
    "    # 'decr_intraTapInt',\n",
    "    # 'mean_intraTapInt',  # out bcs of clustering (in for non-clustering)\n",
    "    # 'decr_tapRMS',  # bcs slope dont steadily incr or decr\n",
    "    # 'slope_tapRMS',\n",
    "    # 'decr_raise_velocity',\n",
    "    # 'slope_raise_velocity',\n",
    "\n",
    "]\n",
    "\n",
    "cv_data = pred_prep.create_X_y_vectors(\n",
    "    USE_FT_CLASS,\n",
    "    incl_traces=USE_FT_CLASS.incl_traces,\n",
    "    incl_feats=CLASS_FEATS,\n",
    "    excl_traces=TRACES_EXCL,\n",
    "    excl_subs=SUBS_EXCL,  # due to hold out data set\n",
    "    to_norm=to_norm,\n",
    "    to_zscore=to_zscore,\n",
    "    to_mask_4=to_mask_4,\n",
    "    return_ids=True,\n",
    "    as_class=True,\n",
    "    mask_nans=True,\n",
    ")\n",
    "\n",
    "# create final dataframe with true and ensemble-predicted labels\n",
    "# default all NaN's, filled during ensemble prediction\n",
    "overall_perf = pd.DataFrame(\n",
    "    data=np.array([[np.nan] * len(cv_data.y)] * 2).T,\n",
    "    columns=['y_true', 'y_pred'],\n",
    "    index=cv_data.ids,\n",
    ")\n",
    "overall_perf['y_true'] = cv_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for missing features (if nans are not masked above)\n",
    "# for i, trace in enumerate(cv_data.ids):\n",
    "\n",
    "#     if np.isnan(cv_data.X[i, :]).any():\n",
    "#         print(trace,\n",
    "#               np.array(CLASS_FEATS)[np.isnan(cv_data.X[i, :])])\n",
    "#         print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONALLY. Split input matrix X_2 in two generated clusters:\n",
    "- split X and y in two groups based on clusters\n",
    "- test default ML modeling on both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs per feat: [0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcluster 0: -0.44354326588319587\n",
      "\tcluster 1: 1.4251554116902685\n",
      "Fast X shape: (196, 14), Slow X shape: (61, 14)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "importlib.reload(get_split)\n",
    "importlib.reload(plot_cluster)\n",
    "importlib.reload(pred_help)\n",
    "\n",
    "# set variables for pre-clustering\n",
    "\n",
    "\n",
    "CLUSTER_FEATS = [\n",
    "    'mean_intraTapInt',\n",
    "    'coefVar_intraTapInt',\n",
    "    'freq'\n",
    "]\n",
    "to_mask_4 = True\n",
    "to_mask_0 = False\n",
    "to_zscore = True\n",
    "to_norm = False\n",
    "\n",
    "# # get dict with dev and hold-out datasets\n",
    "# datasplit_subs = get_split.find_dev_holdout_split(\n",
    "#     feats=USE_FT_CLASS,\n",
    "#     subs_excl=SUBS_EXCL,\n",
    "#     traces_excl=traces_excl,\n",
    "#     choose_random_split=N_RANDOM_SPLIT\n",
    "# )\n",
    "\n",
    "# subs_excl_total = datasplit_subs['hout'].copy()  # both bcs of hold out\n",
    "# subs_excl_total.extend(SUBS_EXCL)  # and bcs of a priori excl\n",
    "\n",
    "# create dataclass for clustering (input matrix, label vector)\n",
    "# only include dev, exclude hold-out\n",
    "cluster_data = pred_prep.create_X_y_vectors(\n",
    "    ftClass=USE_FT_CLASS,\n",
    "    incl_feats=CLUSTER_FEATS,\n",
    "    incl_traces=USE_FT_CLASS.incl_traces,\n",
    "    excl_traces=TRACES_EXCL,\n",
    "    excl_subs=SUBS_EXCL,  # excl hold out data\n",
    "    to_zscore=to_zscore,\n",
    "    to_norm=to_norm,\n",
    "    to_mask_4=to_mask_4,\n",
    "    to_mask_0=to_mask_0,\n",
    "    return_ids=True,\n",
    "    as_class=True\n",
    ")\n",
    "\n",
    "# create cluster labels\n",
    "y_clusters, centr_clust, _ = plot_cluster.get_kMeans_clusters(\n",
    "    X=cluster_data.X,\n",
    "    n_clusters=N_CLUSTERS_FEQ,\n",
    "    use_pca=True,\n",
    "    to_zscore=to_zscore,\n",
    "    to_norm=to_norm,\n",
    ")\n",
    "\n",
    " # split pred_data in two clusters\n",
    "(cv_fast_data, cv_slow_data) = pred_help.split_data_in_clusters(\n",
    "    cv_data, y_clusters, cluster_data, CLUSTER_FEATS\n",
    ")\n",
    "print(f'Fast X shape: {cv_fast_data.X.shape}, Slow X shape: {cv_slow_data.X.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise features in specific clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PUT IN PLOTTING MODULE\n",
    "\n",
    "# create lists for boxplots of features per subscore, per cluster\n",
    "\n",
    "temp_data = cv_data\n",
    "\n",
    "# plot present tap-scores\n",
    "temp_data_scores = [getattr(USE_FT_CLASS, t).tap_score for t in temp_data.ids]\n",
    "temp_data_scores = [getattr(USE_FT_CLASS, t).tap_score for t in temp_data.ids]\n",
    "score_counts = {y: temp_data_scores.count(y) for y in set(temp_data_scores)}\n",
    "plt.bar(score_counts.keys(), score_counts.values())\n",
    "plt.close()\n",
    "\n",
    "box_lists = {}\n",
    "for f in range(temp_data.X.shape[1]):\n",
    "    box_lists[f] = {}\n",
    "    for i in range(4): box_lists[f][i] = []\n",
    "\n",
    "\n",
    "for i in np.arange(temp_data.X.shape[0]):\n",
    "\n",
    "    score = temp_data.y[i]\n",
    "\n",
    "    for f in range(temp_data.X.shape[1]):\n",
    "\n",
    "        if np.logical_and(\n",
    "            CLASS_FEATS[f].startswith('slope') or CLASS_FEATS[f].startswith('decr'),\n",
    "            'entr' in CLASS_FEATS[f] or 'jerk' in CLASS_FEATS[f] or 'intraTap' in CLASS_FEATS[f]\n",
    "        ):\n",
    "            box_lists[f][int(score)].append(abs(temp_data.X[i, f]))\n",
    "\n",
    "        else:\n",
    "            box_lists[f][int(score)].append(temp_data.X[i, f])\n",
    "\n",
    "# plot features within cluster, and decide on strategy\n",
    "# pm: use pre-knowledge about clusters\n",
    "# likelihood in faster cluster for 1-2 scores\n",
    "# use probabilities and adapt the threshold for acceptance\n",
    "# start finding border scores (e.g. 1 or 3)\n",
    "\n",
    "for i_f, ft in enumerate(CLASS_FEATS):\n",
    "\n",
    "    plot_lists = [box_lists[i_f][i] for i in range(4)]\n",
    "\n",
    "    plt.boxplot(plot_lists)\n",
    "    plt.title(ft)\n",
    "    plt.xticks(range(1, len(plot_lists) + 1), labels=['0', '1', '2', '3+4'])\n",
    "    plt.xlabel('UPDRS tap-score')\n",
    "    plt.ylabel('Z-score (a.u.)')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test hierarchichal prediction with Random Forest\n",
    "\n",
    "- Boolean Classification seemed inferior compared to MultiClass RF\n",
    "\n",
    "    optimal thresholds (to prevent too large False Positive Values)\n",
    "    predicting the best tappers (0-1)\n",
    "    - (best) RandomForest, cutoff .75 (TPR ~ .75-.8, FPR ~ .15)\n",
    "    - .58 - .6 for LogReg\n",
    "    - .6 for svm linear kernel\n",
    "    - .6 for svm poly kernel\n",
    "\n",
    "    indicating updrs 3 chance for next step\n",
    "    - .15 for log reg and lda (svc not succesful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tap_predict import retap_cv_models as cv_models\n",
    "from tap_plotting import plot_cv_folds as plot_folds\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Fast Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score as kappa  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 130, test 66\n",
      "Fold 1: # of samples: train 131, test 65\n",
      "Fold 2: # of samples: train 131, test 65\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_fast_data  # data to use here\n",
    "score_to_predict = 3\n",
    "clf_choice = 'RF'\n",
    "nFolds = 3\n",
    "to_plot = True\n",
    "\n",
    "multiclass = True\n",
    "\n",
    "if multiclass:\n",
    "    y_pred_true = temp_data.y\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "else:\n",
    "    if score_to_predict == 1:\n",
    "        y_pred_true = temp_data.y <= score_to_predict\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        y_pred_true = temp_data.y == score_to_predict\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    " y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_pred_true,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "# mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "# print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "#         f' (+/- {round(std_pen, 2)})')\n",
    "# y_true_temp, y_pred_temp = [], []\n",
    "\n",
    "# for f in np.arange(len(y_true_dict)):\n",
    "#     y_true_temp.extend(y_true_dict[f])\n",
    "#     y_pred_temp.extend(y_pred_dict[f])\n",
    "\n",
    "# k_score = kappa(y_true_temp, y_pred_temp, weights='linear')\n",
    "# fast_true = y_true_temp\n",
    "# fast_pred = y_pred_temp\n",
    "\n",
    "# print(f'Kappa: {k_score}, '\n",
    "#       f'R: {scipy.stats.spearmanr(y_true_temp, y_pred_temp)}')\n",
    "\n",
    "# jitt = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# jitt2 = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# plt.scatter(y_true_temp+jitt, y_pred_temp+jitt2)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Slow Tapper Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included # of traces: 61\n",
      "\tscore 0: # 5 (8 %)\n",
      "\tscore 1: # 12 (20 %)\n",
      "\tscore 2: # 24 (39 %)\n",
      "\tscore 3: # 20 (33 %)\n",
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 40, test 21\n",
      "Fold 1: # of samples: train 41, test 20\n",
      "Fold 2: # of samples: train 41, test 20\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_slow_data  # data to use here\n",
    "clf_choice = 'RF'\n",
    "nFolds = 3\n",
    "mask_0 = False\n",
    "multiclass = True\n",
    "score_to_predict = 3\n",
    "\n",
    "y_model = temp_data.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model == score_to_predict\n",
    "    to_plot = True\n",
    "\n",
    "    if score_to_predict == 1:\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "# print descriptives\n",
    "n_samples = len(temp_data.ids)\n",
    "print(f'Included # of traces: {n_samples}')\n",
    "y_scores, counts = np.unique(y_model, return_counts=True)\n",
    "for s, c in zip(y_scores, counts):\n",
    "    print(f'\\tscore {s}: # {c} ({round(c / n_samples * 100)} %)')\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    " y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_model,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "# mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "# print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "#         f' (+/- {round(std_pen, 2)})')\n",
    "\n",
    "\n",
    "\n",
    "# y_true_temp, y_pred_temp = [], []\n",
    "\n",
    "# for f in np.arange(len(y_true_dict)):\n",
    "#     y_true_temp.extend(y_true_dict[f])\n",
    "#     y_pred_temp.extend(y_pred_dict[f])\n",
    "\n",
    "# k_score = kappa(y_true_temp, y_pred_temp, weights='linear')\n",
    "# slow_true = y_true_temp\n",
    "# slow_pred = y_pred_temp\n",
    "\n",
    "# print(f'Kappa: {k_score}, '\n",
    "#       f'R: {scipy.stats.spearmanr(y_true_temp, y_pred_temp)}')\n",
    "\n",
    "# jitt = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# jitt2 = np.random.uniform(low=-.2, high=0.2, size=len(y_true_temp))\n",
    "# plt.scatter(y_true_temp+jitt, y_pred_temp+jitt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### COMBINE FAST AND SLOW CLUSTER OUTCOMES\n",
    "\n",
    "# true_clusters = [l for l in [fast_true, slow_true, y_true_fewTaps]]\n",
    "# true_clusters = [s for l in true_clusters for s in l]\n",
    "\n",
    "# pred_clusters = [l for l in [fast_pred, slow_pred, y_pred_fewTaps]]\n",
    "# pred_clusters = [s for l in pred_clusters for s in l]\n",
    "\n",
    "# cm = cv_models.multiclass_conf_matrix(\n",
    "#       y_true=true_clusters, y_pred=pred_clusters,\n",
    "#       labels=mc_labels,\n",
    "# )\n",
    "# print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "# mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "# print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "#         f' (+/- {round(std_pen, 2)})')\n",
    "\n",
    "# print(f'Kappa: {k_score}, '\n",
    "#       f'R: {scipy.stats.spearmanr(true_clusters, pred_clusters)}')\n",
    "\n",
    "# jitt = np.random.uniform(low=-.2, high=0.2, size=len(true_clusters))\n",
    "# jitt2 = np.random.uniform(low=-.2, high=0.2, size=len(pred_clusters))\n",
    "# plt.scatter(true_clusters+jitt, pred_clusters+jitt2)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# im = ax.imshow(cm.values)\n",
    "\n",
    "# # Show all ticks and label them with the respective list entries\n",
    "# ax.xaxis.tick_top()\n",
    "# ax.set_xticks(np.arange(len(mc_labels)))\n",
    "# ax.set_yticks(np.arange(len(mc_labels)))\n",
    "# ax.set_xticklabels(mc_labels, weight='bold', fontsize=fs)\n",
    "# ax.set_yticklabels(mc_labels, weight='bold', fontsize=fs, )\n",
    "# ax.xaxis.set_label_position('top')\n",
    "# ax.set_xlabel('True UPDRS Tap Score', weight='bold', fontsize=fs, )\n",
    "# ax.set_ylabel('Predicted UPDRS Tap Score', weight='bold', fontsize=fs)\n",
    "\n",
    "# # Loop over data dimensions and create text annotations.\n",
    "# for i in range(len(mc_labels)):\n",
    "#     for j in range(len(mc_labels)):\n",
    "#         value = cm.values[i, j]\n",
    "#         if value > 30: txt_col ='k'\n",
    "#         else: txt_col = 'w'\n",
    "#         text = ax.text(\n",
    "#             j, i, value, weight='bold', fontsize=fs,\n",
    "#             ha=\"center\", va=\"center\", color=txt_col,\n",
    "#       )\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test all Tappers (without clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "ADD_FEW_TAPS = True\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_data  # data to use here\n",
    "clf_choice = 'RF'\n",
    "nFolds = 6\n",
    "mask_0 = False\n",
    "multiclass = True\n",
    "score_to_predict = 3\n",
    "to_plot=True\n",
    "\n",
    "y_model = temp_data.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model == score_to_predict\n",
    "    to_plot = True\n",
    "\n",
    "    if score_to_predict == 1:\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    "y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_model,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    "    verbose=False,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "        # verbose=False,\n",
    "    )\n",
    "if multiclass:\n",
    "\n",
    "    if ADD_FEW_TAPS:\n",
    "        n_dict = nFolds\n",
    "        y_true_dict[n_dict] = y_true_fewTaps\n",
    "        y_pred_dict[n_dict] = y_pred_fewTaps\n",
    "\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tap_plotting.plot_pred_results as plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(plot_results)\n",
    "# y_true_temp, y_pred_temp = [], []\n",
    "\n",
    "# for f in np.arange(len(y_true_dict)):\n",
    "#     y_true_temp.extend(y_true_dict[f])\n",
    "#     y_pred_temp.extend(y_pred_dict[f])\n",
    "\n",
    "# k_score = kappa(y_true_temp, y_pred_temp, weights='linear')\n",
    "# R, R_p = scipy.stats.spearmanr(y_true_temp, y_pred_temp)\n",
    "\n",
    "\n",
    "\n",
    "# plot_results.plot_confMatrix_scatter(\n",
    "#     y_true_temp, y_pred_temp,\n",
    "#     R=R, K=k_score, CM=cm,\n",
    "#     to_save=False, to_show=True, fname='Unclustered'\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Significance using Permutation Tests with shuffeld labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retap_utils.utils_dataManagement import find_onedrive_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Create Permutation Results based on random picking of outcome without Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Penalty without distribution knowledge: 1.134\n",
      "Penalty alpha .05 cut off without distribution knowledge: 1.06\n"
     ]
    }
   ],
   "source": [
    "n_permutations = 500\n",
    "\n",
    "penalties_full_chance = []\n",
    "true_labels = overall_perf['y_true'].values\n",
    "\n",
    "r_states = np.linspace(0, 1000, n_permutations).astype(int)\n",
    "\n",
    "for r_seed in r_states:\n",
    "    np.random.seed(r_seed)\n",
    "    random_labels = np.random.randint(0, 3 + 1, size=len(true_labels))\n",
    "    diffs = abs(true_labels - random_labels)\n",
    "    penalties_full_chance.append(diffs.mean())\n",
    "\n",
    "print(\n",
    "    'Mean Penalty without distribution'\n",
    "    f' knowledge: {round(np.mean(penalties_full_chance), 3)}')\n",
    "print(\n",
    "    'Penalty alpha .05 cut off without distribution'\n",
    "    f' knowledge: {round(np.percentile(penalties_full_chance, 5), 3)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Create MultiClass Permutation Results based Classification of Shuffled or Random Labels\n",
    "\n",
    "- Optionally: Population-Matched (weighted) Distribution of UPDRS scores\n",
    "- TODO: Repeat with n_permutations = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start permutation iteration 0 (random seed 1)\n",
      "Start permutation iteration 1 (random seed 1489)\n",
      "Permutations succesfully saved as: PermErrors_CvDevData_RF_n2_randomLabels\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "\"\"\"\n",
    "Run permutation test\n",
    "    +/- 3-5 seconds per permutation round\n",
    "\"\"\"\n",
    "\n",
    "# Permutation settings\n",
    "random_base_seed = 27  # never changes, to ensure same results in randomisation\n",
    "n_permutations = 2\n",
    "match_label_distribution = False  # take same UPDRS score distribution as real labels\n",
    "to_save_perms = True\n",
    "# CV settings\n",
    "clf_choice = 'RF'\n",
    "nFolds = 6\n",
    "mask_0 = False\n",
    "\n",
    "\n",
    "# Perm settings\n",
    "np.random.seed(random_base_seed)\n",
    "perm_errors = {'mean': [], 'lists': []}\n",
    "r_states = np.random.choice(5000, size=n_permutations, replace=False)\n",
    "\n",
    "# CLassification Settings\n",
    "y_orig = cv_data.y.copy()  # multiclass labels 0-1-2-3(4)\n",
    "X_orig = cv_data.X.copy()\n",
    "\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    min_label = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    min_label = 0\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "# Perform Permutations\n",
    "for n_prm, r_seed in enumerate(r_states):\n",
    "    print(f'Start permutation iteration {n_prm} (random seed {r_seed})')\n",
    "    np.random.seed(r_seed)\n",
    "    # Create random y-labels\n",
    "    if match_label_distribution:\n",
    "        # Create random y-labels with same distribution of scores\n",
    "        y_perm = y_orig.copy()  # copy true y-labels\n",
    "        np.random.shuffle(y_perm)  # shuffle true y-labels\n",
    "\n",
    "    elif not match_label_distribution:\n",
    "        # take random set of labels between 0 and (incl) 3\n",
    "        y_perm = np.random.randint(min_label, 3 + 1, size=len(true_labels))\n",
    "\n",
    "    # Perform random Classification\n",
    "    (y_pred_dict,\n",
    "     y_proba_dict,\n",
    "     y_true_dict,\n",
    "     og_pred_idx) = cv_models.get_cvFold_predictions_dicts(\n",
    "        X_cv=X_orig,\n",
    "        y_cv=y_perm,\n",
    "        cv_method=StratifiedKFold,\n",
    "        n_folds=nFolds,\n",
    "        clf=clf_choice,\n",
    "        verbose=False,\n",
    "    )\n",
    "    # Create MultiClass Conf Matrix\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    (mean_error,\n",
    "     std_error,\n",
    "     error_list) = cv_models.get_penalties_from_conf_matr(cm)\n",
    "    # Add permuted scores to lists\n",
    "    perm_errors['mean'].append(mean_error)\n",
    "    perm_errors['lists'].append(error_list)\n",
    "\n",
    "if to_save_perms:\n",
    "    save_dir = os.path.join(find_onedrive_path('results'),\n",
    "                            'predictions', 'permutations')\n",
    "    fname = f'PermErrors_CvDevData_{clf_choice}_n{n_permutations}'\n",
    "    if match_label_distribution: fname += '_weightedLabels'\n",
    "    else: fname += '_randomLabels'\n",
    "\n",
    "    if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "    temp = np.array(perm_errors['lists'])\n",
    "    temp = pd.DataFrame(temp.T)  # rows are n-samples, columns are n-perms\n",
    "    # np.savetxt(\n",
    "    temp.to_csv(os.path.join(save_dir, f'{fname}.csv'),\n",
    "                sep=',', header=False, index=False,\n",
    "                float_format=np.float32)\n",
    "    print(f'Permutations succesfully saved as: {fname}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Load and Plot Prediction Results vs Permutation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retap_utils.utils_dataManagement import find_onedrive_path\n",
    "\n",
    "n_perm = 5\n",
    "alpha = .05\n",
    "save_fig=False\n",
    "\n",
    "# fname = f'PermErrors_CvDevData_{clf_choice}_n{n_permutations}'\n",
    "# if match_label_distribution: fname += '_weightedLabels'\n",
    "# else: fname += '_randomLabels'\n",
    "# fname = f'RF_full_dev_data_{n_perm}perms_means.csv'\n",
    "fname = 'PermErrors_CvDevData_RF_n5_weightedLabels.csv'\n",
    "perm_dir = os.path.join(\n",
    "    find_onedrive_path('results'),\n",
    "    'predictions', 'permutations')\n",
    "\n",
    "# get mean error per permutation iteration\n",
    "perm_error_lists = np.genfromtxt(os.path.join(perm_dir, fname), delimiter=',')\n",
    "if perm_error_lists.shape[0] == n_perm:\n",
    "    mean_errors = perm_error_lists.mean(axis=1)\n",
    "elif perm_error_lists.shape[1] == n_perm:\n",
    "    mean_errors = perm_error_lists.mean(axis=0)\n",
    "else:\n",
    "    raise ValueError('Incorrect # shape of loaded Permutation Errors')\n",
    "# get alpha significance border\n",
    "sign_05 = round(np.percentile(mean_errors, alpha * 100), 2)\n",
    "\n",
    "# Plot Results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "\n",
    "ymin, ymax = ax.get_ylim()\n",
    "# plot Real cross-validation prediction mean\n",
    "ax.axvline(.74, lw=3, ymin=ymin, ymax=ymax, color='darkgreen',\n",
    "           label=f'mean (unclustered)\\ncross-val predictions')\n",
    "# plot permutation test results\n",
    "ax.hist(mean_errors, color='darkblue', hatch='/', alpha=.5,\n",
    "        label=f'balanced permutations -\\nprediction means (n={n_perm})',)\n",
    "# ax.hist(penalties_full_chance, color='purple', hatch='//', alpha=.2,\n",
    "#         label=f'unbalanced permutations -\\nprediction means (n={n_perm})',)\n",
    "ax.axvline(sign_05, ymin=ymin, ymax=ymax, color='darkblue',\n",
    "           ls='--', label=f'alpha=0.05\\n(balanced)')\n",
    "# ax.axvline(1.06, ymin=ymin, ymax=ymax, color='purple',\n",
    "#            ls='--', label=f'alpha=0.05\\n(unbalanced)')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Mean Prediction Error (UPDRS tap-score)')\n",
    "ax.set_ylabel('observations (#)')\n",
    "ax.legend(frameon=False, fontsize=12, ncol=1,\n",
    "          bbox_to_anchor=(.90, .99), loc='upper left',)\n",
    "for side in ['right', 'top']:\n",
    "    getattr(ax.spines, side).set_visible(False)\n",
    "plt.xlim(.65, 1.3)\n",
    "plt.ylim(0, 50)\n",
    "plt.tight_layout()\n",
    "if save_fig:\n",
    "    fname='RF_prediction_vs_200permutations_test'\n",
    "    plt.savefig(\n",
    "        os.path.join(find_onedrive_path('figures'),\n",
    "                    'prediction', fname),\n",
    "        facecolor='w', dpi=150,)\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Agreements with Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score as kappa  # k_score = kappa(y_true, y_pred)  # 1 is perfect, 0 is chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOLDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASPLIT = 'HOLDOUT'\n",
    "\n",
    "FT_CLASS_DATE = '20230228'\n",
    "ftClass_name = f'ftClass_ALL_{FT_CLASS_DATE}.P'\n",
    "\n",
    "CLUSTER_ON_FREQ = True\n",
    "USE_MODEL_DATE = '20230303'\n",
    "STD_PARAMS = f'{USE_MODEL_DATE}_STD_params_alltaps.csv'\n",
    "CLUSTER_STD_PARAMS = f'{USE_MODEL_DATE}_STD_params_cluster_alltaps.csv'\n",
    "\n",
    "SCORE_FEW_TAPS_3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_FEATS = [\n",
    "    'trace_RMSn',\n",
    "    'trace_entropy',\n",
    "    'jerkiness_trace',\n",
    "    'coefVar_intraTapInt',\n",
    "    'slope_intraTapInt',\n",
    "    'mean_tapRMS',\n",
    "    'coefVar_tapRMS',\n",
    "    'mean_impactRMS',\n",
    "    'coefVar_impactRMS',\n",
    "    'slope_impactRMS',\n",
    "    'mean_raise_velocity',\n",
    "    'coefVar_raise_velocity',\n",
    "    'coefVar_tap_entropy',\n",
    "    'slope_tap_entropy',\n",
    "]\n",
    "\n",
    "CLUSTER_FEATS = [\n",
    "    'mean_intraTapInt',\n",
    "    'coefVar_intraTapInt',\n",
    "    'freq'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING DATA IN DEV AND HOLD-OUT\n",
      "Original score distribution: {0: 40, 1: 149, 2: 106, 3: 55, 4: 1}\n",
      "Original score %: {0: 11.4, 1: 42.5, 2: 30.2, 3: 15.7, 4: 0.3}\n",
      "Accepted Split: random state 41\n",
      "\n",
      "Resulting distributions in splitted data sets:\n",
      "\n",
      "\tdev data set (n = 263):\n",
      "score 0: # 30 (11 %)\n",
      "score 1: # 109 (41 %)\n",
      "score 2: # 81 (31 %)\n",
      "score 3: # 43 (16 %)\n",
      "score 4: # 0 (0 %)\n",
      "\thout data set (n = 89):\n",
      "score 0: # 10 (11 %)\n",
      "score 1: # 40 (45 %)\n",
      "score 2: # 26 (29 %)\n",
      "score 3: # 12 (13 %)\n",
      "score 4: # 1 (1 %)\n"
     ]
    }
   ],
   "source": [
    "FT_CLASS = utils_dataManagement.load_class_pickle(\n",
    "    os.path.join(utils_dataManagement.get_local_proj_dir(),\n",
    "         'data', 'derivatives', ftClass_name)\n",
    ")\n",
    "\n",
    "SUBS_EXCL = ['BER028']  # too many missing acc-data\n",
    "TRACES_EXCL = ['DUS006_M0S0_L_1']  # no score/video\n",
    "\n",
    "### GET DATA SPLIT CROSS-VAL OR HOLD-OUT\n",
    "datasplit_subs = get_split.find_dev_holdout_split(\n",
    "    feats=FT_CLASS,\n",
    "    subs_excl=SUBS_EXCL,\n",
    "    traces_excl=TRACES_EXCL,\n",
    "    # choose_random_split=N_RANDOM_SPLIT\n",
    ")\n",
    "\n",
    "if DATASPLIT == 'CROSSVAL':\n",
    "    datasplit_subs_incl = datasplit_subs['dev']\n",
    "    datasplit_subs_excl = datasplit_subs['hout']\n",
    "    params_df=None  # necessary for function to run in cv\n",
    "    cluster_params_df=None  # necessary for function to run in cv\n",
    "elif DATASPLIT == 'HOLDOUT':\n",
    "    datasplit_subs_incl = datasplit_subs['hout']\n",
    "    datasplit_subs_excl = datasplit_subs['dev']\n",
    "    params_df = pd.read_csv(os.path.join(utils_dataManagement.get_local_proj_dir(),\n",
    "                              'results', 'models', STD_PARAMS),\n",
    "                         header=0, index_col=0,)\n",
    "    if CLUSTER_ON_FREQ:\n",
    "        cluster_params_df = pd.read_csv(os.path.join(utils_dataManagement.get_local_proj_dir(),\n",
    "                                        'results', 'models', CLUSTER_STD_PARAMS),\n",
    "                                    header=0, index_col=0,)\n",
    "#\n",
    "SUBS_EXCL.extend(datasplit_subs_excl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXCLUDE TRACES with SMALL NUMBER of TAPS, CLASSIFY them AS \"3\"\n",
    "if SCORE_FEW_TAPS_3:\n",
    "    (classf_taps_3,\n",
    "     y_pred_fewTaps,\n",
    "     y_true_fewTaps\n",
    "    ) = pred_help.classify_based_on_nTaps(\n",
    "        max_n_taps=9,\n",
    "        ftClass=FT_CLASS,\n",
    "        )\n",
    "    # select traces from subs present in current datasplit\n",
    "    sel = [\n",
    "        np.array([t.startswith(s) for s in datasplit_subs_incl]).any()\n",
    "        for t in classf_taps_3\n",
    "    ]\n",
    "    TRACES_EXCL.extend(list(compress(classf_taps_3, sel)))  # exclude classified traces from prediction\n",
    "    y_pred_fewTaps = list(compress(y_pred_fewTaps, sel))  # store predicted value and true values\n",
    "    y_true_fewTaps = list(compress(y_true_fewTaps, sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 14)\n",
      "# of NaNs per feat: [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "### CREATE DATA FOR PREDICTION (considers datasplit and excl-too-few-taps)\n",
    "pred_data = pred_prep.create_X_y_vectors(\n",
    "    FT_CLASS,\n",
    "    incl_traces=FT_CLASS.incl_traces,\n",
    "    incl_feats=CLASS_FEATS,\n",
    "    excl_traces=TRACES_EXCL,\n",
    "    excl_subs=SUBS_EXCL,  # contains data-split exclusion and too-few-tap-exclusion\n",
    "    to_norm=False,\n",
    "    to_zscore=True,\n",
    "    to_mask_4=True,\n",
    "    return_ids=True,\n",
    "    as_class=True,\n",
    "    mask_nans=True,\n",
    "    save_STD_params=False,\n",
    "    use_STD_params_df=params_df,  # only gives ft-mean/-sd in HOLDOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 3)\n",
      "# of NaNs per feat: [0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcluster 0: -0.7042764997085783\n",
      "\tcluster 1: 1.4353529415870507\n"
     ]
    }
   ],
   "source": [
    "cluster_data = pred_prep.create_X_y_vectors(\n",
    "    FT_CLASS,\n",
    "    incl_traces=FT_CLASS.incl_traces,\n",
    "    incl_feats=CLUSTER_FEATS,\n",
    "    excl_traces=TRACES_EXCL,\n",
    "    excl_subs=SUBS_EXCL,  # includes excluding of HOLDOUT OR CROSSVAL\n",
    "    to_zscore=True,\n",
    "    to_mask_4=True,\n",
    "    return_ids=True,\n",
    "    as_class=True,\n",
    "    save_STD_params=False,\n",
    "    use_STD_params_df=cluster_params_df,  # only gives ft-mean/-sd in HOLDOUT\n",
    ")\n",
    "\n",
    "# create cluster labels\n",
    "y_clusters, _, _ = plot_cluster.get_kMeans_clusters(\n",
    "    X=cluster_data.X, n_clusters=2,\n",
    ")\n",
    "# split pred_data in two clusters\n",
    "(fast_pred_data, slow_pred_data) = pred_help.split_data_in_clusters(\n",
    "    pred_data, y_clusters, cluster_data.X, CLUSTER_FEATS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tap_predict.perform_holdout import perform_holdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME_FAST = f'{USE_MODEL_DATE}_RF_CLUSTERED_FAST_alltaps.P'\n",
    "# MODEL_NAME_SLOW = f'{USE_MODEL_DATE}_RF_CLUSTERED_SLOW_alltaps.P'\n",
    "# MODEL_NAME = f'{USE_MODEL_DATE}_RF_UNCLUSTERED_alltaps.P'\n",
    "\n",
    "\n",
    "# if not CLUSTER_ON_FREQ:\n",
    "#     y_true_dict, y_pred_dict = perform_holdout(\n",
    "#         full_X=pred_data.X, full_y=pred_data.y,\n",
    "#         full_modelname=MODEL_NAME\n",
    "#     )\n",
    "\n",
    "# elif CLUSTER_ON_FREQ:\n",
    "#     y_true_dict, y_pred_dict = perform_holdout(\n",
    "#         slow_X=slow_pred_data.X, slow_y=slow_pred_data.y,\n",
    "#         fast_X=fast_pred_data.X, fast_y=fast_pred_data.y,\n",
    "#         slow_modelname=MODEL_NAME_SLOW,\n",
    "#         fast_modelname=MODEL_NAME_FAST,\n",
    "#     )\n",
    "# print(y_true_dict)\n",
    "# # add traces classified on few-taps as separate dict fold\n",
    "# if SCORE_FEW_TAPS_3:\n",
    "#     y_true_dict['fewtaps'] = y_true_fewTaps\n",
    "#     y_pred_dict['fewtaps'] = y_pred_fewTaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tap_predict.retap_cv_models' from 'c:\\\\Users\\\\habetsj\\\\Research\\\\projects\\\\tapping\\\\code\\\\updrsTapping_repo\\\\tap_predict\\\\retap_cv_models.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cv_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc_labels=['0', '1', '2', '3-4']\n",
    "# for key in y_true_dict:\n",
    "#     print(key)\n",
    "#     print('TRUE', y_true_dict[key])\n",
    "#     print('PRED', y_pred_dict[key])\n",
    "#     print(cv_models.multiclass_conf_matrix(\n",
    "#             y_true=y_true_dict[key], y_pred=y_pred_dict[key],\n",
    "#             labels=mc_labels,\n",
    "#         ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) PM Traditional Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Candidate vetors based on descriptives and concept\n",
    "    - nTaps\n",
    "    - freq\n",
    "    - upVelo sum [std-dev + coefVar]\n",
    "    - impact RMS [coefVar + stddev]\n",
    "    - tapRMS and impactRMS [sum]\n",
    "    - \n",
    "- include per run (array tap-features): sum, mean, stddev, trend_slope\n",
    "\n",
    "- Cluster on UPDRS 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANOVA\n",
    "\n",
    "- normality assumption violated (Shapiro test highly significant)\n",
    "- for every a priori selected feature: present difference between sub-score-groups is a Kruskal-Wallis test (non-parametric One-Way ANOVA alternative)\n",
    "- differences between two sub groups within a feature is a non-parametric test of two groups of quantitative values (likely varying lengths): Mann-Whitney-U\n",
    "- in total: correct alpha for number of repeated measures on specific level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import shapiro\n",
    "# for col in np.arange(X.shape[1]):\n",
    "#     print(feats[col], shapiro(X[:, col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "# stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "# manova_df = pd.DataFrame(\n",
    "#     data=stat_data,\n",
    "#     columns=feats + ['subscore'],\n",
    "# )\n",
    "# maov = MANOVA.from_formula(\n",
    "#     'nTaps + freq + mean_intraTapInt + coefVar_intraTapInt + IQR_jerkiness +'\n",
    "#     ' mean_raise_velocity + mean_tapRMSnrm ~ subscore ',\n",
    "#     # 'mean_jerkiness_smooth + IQR_jerkiness_smooth ~ subscore',\n",
    "#     data=manova_df,\n",
    "# )\n",
    "# print(maov.mv_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import kruskal\n",
    "# importlib.reload(pred_prep)\n",
    "\n",
    "# mask_scores = True\n",
    "\n",
    "# traces, feats = pred_prep.select_traces_and_feats(\n",
    "#     ftClass,\n",
    "#     center=center_incl,\n",
    "#     use_sel_fts=sel_feats,\n",
    "# )\n",
    "# X, y = pred_prep.create_X_y_vectors(\n",
    "#     ftClass,\n",
    "#     incl_traces=traces,\n",
    "#     incl_feats=feats,\n",
    "#     to_norm=False,\n",
    "# )\n",
    "# n_groups = 5\n",
    "# if mask_scores:\n",
    "#     # UPDRS 4 -> 3 merge\n",
    "#     mask = y == 4\n",
    "#     y[mask] = 3\n",
    "#     # UPDRS 0 -> 1 merge\n",
    "#     mask = y == 0\n",
    "#     y[mask] = 1\n",
    "\n",
    "#     n_groups = 3\n",
    "\n",
    "# stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "# stat_df = pd.DataFrame(\n",
    "#     data=stat_data,\n",
    "#     columns=feats + ['subscore'],\n",
    "# )\n",
    "\n",
    "# stat_fts = [\n",
    "#     'freq', 'coefVar_intraTapInt', 'mean_jerkiness', 'coefVar_jerkiness',\n",
    "#     'mean_tapRMSnrm', 'coefVar_tapRMSnrm', 'slope_tapRMSnrm'\n",
    "# ]\n",
    "# alpha = .05 / len(stat_fts)\n",
    "# for ft in stat_fts:\n",
    "#     tempft = stat_df[~np.isnan(stat_df[ft])]\n",
    "\n",
    "    \n",
    "#     if mask_scores:\n",
    "#         groups = [\n",
    "#             tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "#             for s in np.arange(1, n_groups + 1)\n",
    "#         ]\n",
    "#         krusk_stat, krusk_p = kruskal(\n",
    "#             groups[0], groups[1], groups[2], \n",
    "#         )\n",
    "#     else:\n",
    "#         groups = [\n",
    "#             tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "#             for s in np.arange(n_groups)\n",
    "#         ]\n",
    "#         krusk_stat, krusk_p = kruskal(\n",
    "#             groups[0], groups[1], groups[2], \n",
    "#             groups[3], groups[4]\n",
    "#         )\n",
    "#     print(f'\\n{ft}: \\n\\tGroup level sign. difference (Kruskal'\n",
    "#         f' Test): {krusk_p < alpha} (p = {np.round(krusk_p, 6)})\\n')\n",
    "#     for g in np.arange(n_groups - 1):\n",
    "\n",
    "#         mnwu_rho, mnwu_p = mannwhitneyu(groups[g], groups[g + 1])\n",
    "#         print(f'\\tupdrs {g} vs {g + 1} sign, (Mann-Whitney-U): '\n",
    "#             f'{mnwu_p < (alpha / (n_groups - 1))} (p = {np.round(mnwu_p, 6)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23a308fb4398211655e9950c8371f856de701ec09eac61c96054832e4a49057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
