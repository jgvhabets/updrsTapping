{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTap - UPDRS-Tapping Assessment - Predictions\n",
    "\n",
    "This notebooks investigates optimal hand- and fingertapping algorithms as part of the \n",
    "ReTune-Dyskinesia project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from array import array\n",
    "import datetime as dt\n",
    "from dataclasses import  dataclass, field\n",
    "from itertools import compress\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 1.4.4\n",
      "numpy 1.23.3\n",
      "sci-py 1.9.1\n",
      "sci-kit learn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "\n",
    "\n",
    "## developed with:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1\n",
    "\n",
    "## Currently (own env) since 31.08.22\n",
    "# Python sys 3.9.12 (main, Jun  1 2022, 06:36:29) \n",
    "# [Clang 12.0.0 ]\n",
    "# pandas 1.4.3\n",
    "# numpy 1.21.5\n",
    "# sci-py 1.7.3\n",
    "# sci-kit learn 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own functions\n",
    "from retap_utils import utils_dataManagement\n",
    "import retap_utils.get_datasplit as get_split\n",
    "\n",
    "import tap_predict.tap_pred_prepare as pred_prep\n",
    "import tap_plotting.retap_plot_clusters as plot_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split development and hold-out-test data sets\n",
    "\n",
    "- Development data is used to train and test the model using iterative cross-validation\n",
    "- Hold-out test data is NOT USED at all during cross-validation, and will be used to test the trained model as an external validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT CREATED CLASSES FROM FILES\n",
    "from tap_extract_fts.main_featExtractionClass import FeatureSet, singleTrace\n",
    "\n",
    "# define path with feature class\n",
    "deriv_path = os.path.join(utils_dataManagement.get_local_proj_dir(), 'data', 'derivatives')\n",
    "\n",
    "ftClass = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_20221214.P'))\n",
    "ftClass10 = utils_dataManagement.load_class_pickle(os.path.join(deriv_path, 'ftClass_ALL_max10_20221214.P'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ML-dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Including ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center='all',\n",
    "    use_sel_fts=True,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Ensemble method, start with clustering on intraTapInterval and overall tapping-frequency\n",
    "\n",
    "Create X1 with selected input features (mean and coef of variation of intra-tap-interval) and\n",
    "overall tapping frequency to find two clusters (y_clusters) dividing fast vs slow tappers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING DATA IN DEV AND HOLD-OUT\n",
      "Original score distribution: {0: 40, 1: 154, 2: 122, 3: 57, 4: 3}\n",
      "Original score %: {0: 10.6, 1: 41.0, 2: 32.4, 3: 15.2, 4: 0.8}\n",
      "Accepted Split: random state 63\n",
      "\n",
      "Resulting distributions in splitted data sets:\n",
      "\n",
      "\tdev data set (n = 285):\n",
      "score 0: # 32 (11 %)\n",
      "score 1: # 115 (40 %)\n",
      "score 2: # 94 (33 %)\n",
      "score 3: # 42 (15 %)\n",
      "score 4: # 2 (1 %)\n",
      "\thout data set (n = 91):\n",
      "score 0: # 8 (9 %)\n",
      "score 1: # 39 (43 %)\n",
      "score 2: # 28 (31 %)\n",
      "score 3: # 15 (16 %)\n",
      "score 4: # 1 (1 %)\n",
      "# of NaNs per feat: [0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean mean_intraTapInt (z-scored):\n",
      "\tcluster 0: -0.357289281961114\n",
      "\tcluster 1: 1.4546777908416781\n",
      "Fast tappers are clustered in cluster index 0\n",
      "Slow tappers are clustered in cluster index 1\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "importlib.reload(get_split)\n",
    "importlib.reload(plot_cluster)\n",
    "\n",
    "# set variables for pre-clustering\n",
    "ftClass_to_use = ftClass10\n",
    "n_clusters = 2\n",
    "traces_excl = [\n",
    "    'DUS006_M0S0_L_1',\n",
    "]\n",
    "ft_sel = [\n",
    "    'mean_intraTapInt',\n",
    "    'coefVar_intraTapInt',\n",
    "    'freq'\n",
    "]\n",
    "to_mask_4 = True\n",
    "to_mask_0 = False\n",
    "to_zscore = True\n",
    "to_norm = False\n",
    "\n",
    "# get dict with dev and hold-out datasets\n",
    "datasplit_subs = get_split.find_dev_holdout_split(\n",
    "    feats=ftClass_to_use, )\n",
    "\n",
    "# create dataclass for clustering (input matrix, label vector)\n",
    "# only include dev, exclude hold-out\n",
    "dev_data = pred_prep.create_X_y_vectors(\n",
    "    ftClass=ftClass_to_use,\n",
    "    incl_feats=ft_sel,\n",
    "    incl_traces=ftClass_to_use.incl_traces,\n",
    "    excl_traces=traces_excl,\n",
    "    excl_subs=datasplit_subs['hout'],  # excl hold out data\n",
    "    to_zscore=to_zscore,\n",
    "    to_norm=to_norm,\n",
    "    to_mask_4=to_mask_4,\n",
    "    to_mask_0=to_mask_0,\n",
    "    return_ids=True,\n",
    "    as_class=True\n",
    ")\n",
    "\n",
    "# create cluster labels\n",
    "y_clust, centr_clust, _ = plot_cluster.get_kMeans_clusters(\n",
    "    X=dev_data.X,\n",
    "    n_clusters=n_clusters,\n",
    "    use_pca=True,\n",
    "    to_zscore=to_zscore,\n",
    "    to_norm=to_norm,\n",
    ")\n",
    "\n",
    "# Define which cluster contains faster tappers\n",
    "cluster_mean_ITIs = []\n",
    "\n",
    "ft = 'mean_intraTapInt'\n",
    "if to_zscore: print(f'Mean {ft} (z-scored):')\n",
    "elif to_norm: print(f'Mean {ft} (normed):')\n",
    "\n",
    "for i_cls in np.unique(y_clust):\n",
    "\n",
    "    i_ft = np.where([f == ft for f in ft_sel])[0][0]\n",
    "    mean_iti_cluster = np.mean(dev_data.X[y_clust == i_cls, i_ft])\n",
    "    cluster_mean_ITIs.append(mean_iti_cluster)\n",
    "\n",
    "    print(f'\\tcluster {i_cls}: {mean_iti_cluster}')\n",
    "\n",
    "fast_cluster_i = np.argmin(cluster_mean_ITIs)\n",
    "if fast_cluster_i == 0: slow_cluster_i = 1\n",
    "if fast_cluster_i == 1: slow_cluster_i = 0\n",
    "\n",
    "print(f'Fast tappers are clustered in cluster index {fast_cluster_i}')\n",
    "print(f'Slow tappers are clustered in cluster index {slow_cluster_i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make X_2 input Matrix with more features for score-prediction per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs per feat: [0 0 0 0 3 0 0]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "incl_traces, ft_list = pred_prep.select_traces_and_feats(\n",
    "    ftClass_to_use, use_sel_fts=True, excl_traces=traces_excl,\n",
    ")\n",
    "\n",
    "feats_for_2nd_pred = [\n",
    "    # 'freq',\n",
    "    'coefVar_intraTapInt',\n",
    "    # 'mean_intraTapInt',\n",
    "    # 'slope_intraTapInt',\n",
    "    'decr_intraTapInt',\n",
    "    'mean_tapRMS',\n",
    "    'coefVar_tapRMS',\n",
    "    # 'slope_tapRMS',\n",
    "    'decr_tapRMS',\n",
    "    'mean_raise_velocity',\n",
    "    'jerkiness_trace'\n",
    "]\n",
    "\n",
    "cv_data = pred_prep.create_X_y_vectors(\n",
    "    ftClass_to_use,\n",
    "    incl_traces=ftClass_to_use.incl_traces,\n",
    "    incl_feats=feats_for_2nd_pred,\n",
    "    excl_traces=traces_excl,\n",
    "    excl_subs=datasplit_subs['hout'],  # due to hold out data set\n",
    "    to_norm=to_norm,\n",
    "    to_zscore=to_zscore,\n",
    "    to_mask_4=to_mask_4,\n",
    "    return_ids=True,\n",
    "    as_class=True,\n",
    ")\n",
    "\n",
    "# create final dataframe with true and ensemble-predicted labels\n",
    "# default all NaN's, filled during ensemble prediction\n",
    "overall_perf = pd.DataFrame(\n",
    "    data=np.array([[np.nan] * len(cv_data.y)] * 2).T,\n",
    "    columns=['y_true', 'y_pred'],\n",
    "    index=cv_data.ids,\n",
    ")\n",
    "overall_perf['y_true'] = cv_data.y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split input matrix X_2 in two generated clusters:\n",
    "- split X and y in two groups based on clusters\n",
    "- test default ML modeling on both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CV X shape: (284, 7)\n",
      "Fast X shape: (228, 7), Slow X shape: (56, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f'Total CV X shape: {cv_data.X.shape}')\n",
    "\n",
    "cv_fast_data = pred_prep.predictionData(\n",
    "    X=cv_data.X[y_clust == fast_cluster_i],\n",
    "    y=cv_data.y[y_clust == fast_cluster_i],\n",
    "    ids=cv_data.ids[y_clust == fast_cluster_i])\n",
    "\n",
    "cv_slow_data = pred_prep.predictionData(\n",
    "    X=cv_data.X[y_clust == slow_cluster_i],\n",
    "    y=cv_data.y[y_clust == slow_cluster_i],\n",
    "    ids=cv_data.ids[y_clust == slow_cluster_i])\n",
    "\n",
    "print(f'Fast X shape: {cv_fast_data.X.shape}, Slow X shape: {cv_slow_data.X.shape}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise features in specific clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for boxplots of features per subscore, per cluster\n",
    "\n",
    "temp_data = cv_fast_data\n",
    "\n",
    "box_lists = {}\n",
    "for f in range(temp_data.X.shape[1]):\n",
    "    box_lists[f] = {}\n",
    "    for i in range(4): box_lists[f][i] = []\n",
    "\n",
    "\n",
    "for i in np.arange(temp_data.X.shape[0]):\n",
    "\n",
    "    score = temp_data.y[i]\n",
    "\n",
    "    for f in range(temp_data.X.shape[1]):\n",
    "\n",
    "        box_lists[f][int(score)].append(temp_data.X[i, f])\n",
    "\n",
    "# plot features within cluster, and decide on strategy\n",
    "# pm: use pre-knowledge about clusters\n",
    "# likelihood in faster cluster for 1-2 scores\n",
    "# use probabilities and adapt the threshold for acceptance\n",
    "# start finding border scores (e.g. 1 or 3)\n",
    "\n",
    "for i_f, ft in enumerate(feats_for_2nd_pred):\n",
    "\n",
    "    plot_lists = [box_lists[i_f][i] for i in range(4)]\n",
    "\n",
    "    plt.boxplot(plot_lists)\n",
    "    plt.title(ft)\n",
    "    plt.xticks(range(1, len(plot_lists) + 1), labels=['0', '1', '2', '3+4'])\n",
    "    plt.xlabel('UPDRS tap-score')\n",
    "    plt.ylabel('Z-score (a.u.)')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different prediction models for second step in Fast Cluster\n",
    "\n",
    "optimal thresholds (to prevent too large False Positive Values)\n",
    "#### predicting the best tappers (0-1)\n",
    "- (best) RandomForest, cutoff .75 (TPR ~ .75-.8, FPR ~ .15)\n",
    "- .58 - .6 for LogReg\n",
    "- .6 for svm linear kernel\n",
    "- .6 for svm poly kernel\n",
    "\n",
    "#### indicating updrs 3 chance for next step\n",
    "- .15 for log reg and lda (svc not succesful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retap_utils.plot_helpers import remove_duplicate_legend\n",
    "from tap_predict import retap_cv_models as cv_models\n",
    "from tap_plotting import plot_cv_folds as plot_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, roc_curve,\n",
    "    accuracy_score, f1_score, precision_score,\n",
    "    recall_score, plot_roc_curve, plot_confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true,y_preds).ravel()\n",
    "# # add outcomes to dedicated lists\n",
    "# ['Accuracy'].append(accuracy_score(y_true,y_preds))\n",
    "# ['AUROC'].append(roc_auc_score(y_true, y_probas[1]))\n",
    "# ['F1_score'].append(f1_score(y_true,y_preds))\n",
    "# ['Precision'].append(precision_score(y_true, y_preds)) # precision/PPV\n",
    "# ['Recall'].append(recall_score(y_true, y_preds)) # sensitivity/recall/TPR\n",
    "# ['FPR'].append(fp / (fp+tn)) # false-positive, false-alarm rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_dev: (228, 7)\n",
      "predicting UPDRS score 1\n",
      "total y true: 324\n",
      "Chance level: 1.421\n",
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 171, test 57\n",
      "Fold 1: # of samples: train 171, test 57\n",
      "Fold 2: # of samples: train 171, test 57\n",
      "Fold 3: # of samples: train 171, test 57\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_fast_data  # data to use here\n",
    "score_to_predict = 1\n",
    "clf_choice = 'RF'\n",
    "nFolds = 4\n",
    "to_plot = True\n",
    "\n",
    "multiclass = True\n",
    "\n",
    "if multiclass:\n",
    "    y_pred_true = temp_data.y\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "else:\n",
    "    if score_to_predict == 1:\n",
    "        y_pred_true = temp_data.y <= score_to_predict\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        y_pred_true = temp_data.y == score_to_predict\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "\n",
    "chance = round(sum(y_pred_true) / len(y_pred_true), 3)\n",
    "print(f'shape of X_dev: {temp_data.X.shape}')\n",
    "print(f'predicting UPDRS score {score_to_predict}')\n",
    "print(f'total y true: {sum(y_pred_true)}')\n",
    "print(f'Chance level: {chance}')\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    " y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_pred_true,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    # print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "    # mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "    # print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "    #         f' (+/- {round(std_pen, 2)})')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract best tappers (0-1 predicted) from fast-tappers and classify remaining part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pred_prep)\n",
    "\n",
    "# Set Final Prediction best fast-tappers to 1\n",
    "set_outcome = True\n",
    "data_fast_01, data_fast_rest = pred_prep.split_dataset_on_pred_proba(\n",
    "    orig_dataset=cv_fast_data,\n",
    "    probas=y_proba_dict,\n",
    "    og_indices=og_pred_idx,\n",
    "    proba_thr=.75,\n",
    ")\n",
    "if set_outcome:\n",
    "    for trace_id in data_fast_01.ids:\n",
    "        overall_perf.at[trace_id, 'y_pred'] = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify UPDRS 3 in remaining fast tappers\n",
    "\n",
    "- use positive prediction for UPDRS III in previous step (which is not used for splitting data)\n",
    "- opt logreg threshold for updrs-3: .18\n",
    "- opt lda threshold for updrs-3: .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining # of traces: 168\n",
      "\tscore 0: # 18 (11 %)\n",
      "\tscore 1: # 59 (35 %)\n",
      "\tscore 2: # 69 (41 %)\n",
      "\tscore 3: # 22 (13 %)\n",
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 112, test 56\n",
      "Fold 1: # of samples: train 112, test 56\n",
      "Fold 2: # of samples: train 112, test 56\n"
     ]
    }
   ],
   "source": [
    "### INCLUDE UPDRS 3 LABELS FROM RPEVIOUS TEP\n",
    "\n",
    "importlib.reload(cv_models)\n",
    "n_samples = len(data_fast_rest.ids)\n",
    "print(f'Remaining # of traces: {n_samples}')\n",
    "y_scores, counts = np.unique(data_fast_rest.y, return_counts=True)\n",
    "for s, c in zip(y_scores, counts):\n",
    "    print(f'\\tscore {s}: # {c} ({round(c / n_samples * 100)} %)')\n",
    "\n",
    "\n",
    "multiclass = True\n",
    "clf_choice = 'rf'\n",
    "to_plot=True\n",
    "mask_0 = True\n",
    "\n",
    "y_model = data_fast_rest.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model >= 2\n",
    "\n",
    "plot_thresholds=[.5, .6, .7]\n",
    "roc_title=f'Rest Fast-Tappers == UPDRS 2/3 ({clf_choice})'\n",
    "\n",
    "\n",
    "(cv_pred, cv_proba, cv_true, cv_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=data_fast_rest.X,\n",
    "    y_cv=y_model,\n",
    "    n_folds=3,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "\n",
    "if clf_choice == 'lda': thresh3 = .3\n",
    "elif clf_choice == 'logreg': thresh3 = .3\n",
    "\n",
    "ids_pos_3 = []\n",
    "for fold in cv_proba:\n",
    "    for i_prob, proba in enumerate(cv_proba[fold]):\n",
    "        if proba[1] > thresh3:\n",
    "            og_i = cv_idx[fold][i_prob]\n",
    "            ids_pos_3.append(\n",
    "                data_fast_rest.ids[og_i]\n",
    "            )\n",
    "\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=cv_true,\n",
    "        y_proba_dict=cv_proba,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "        incl_mean_ROC=True,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=cv_true, y_pred=cv_pred,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    # print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "    # mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "    # print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "    #         f' (+/- {round(std_pen, 2)})')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Slow Tapper Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included # of traces: 56\n",
      "\tscore 1: # 20 (36 %)\n",
      "\tscore 2: # 16 (29 %)\n",
      "\tscore 3: # 20 (36 %)\n",
      "RandomForestClassifier(class_weight='balanced', min_samples_split=5,\n",
      "                       n_estimators=500, random_state=27)\n",
      "Fold 0: # of samples: train 37, test 19\n",
      "Fold 1: # of samples: train 37, test 19\n",
      "Fold 2: # of samples: train 38, test 18\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_slow_data  # data to use here\n",
    "clf_choice = 'RF'\n",
    "nFolds = 3\n",
    "mask_0 = True\n",
    "multiclass = True\n",
    "score_to_predict = 3\n",
    "\n",
    "y_model = temp_data.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model == score_to_predict\n",
    "    to_plot = True\n",
    "\n",
    "    if score_to_predict == 1:\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "# print descriptives\n",
    "n_samples = len(temp_data.ids)\n",
    "print(f'Included # of traces: {n_samples}')\n",
    "y_scores, counts = np.unique(y_model, return_counts=True)\n",
    "for s, c in zip(y_scores, counts):\n",
    "    print(f'\\tscore {s}: # {c} ({round(c / n_samples * 100)} %)')\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    " y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_model,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    # print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "    # mean_pen, std_pen, _ = cv_models.get_penalties_from_conf_matr(cm)\n",
    "    # print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "    #         f' (+/- {round(std_pen, 2)})')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test all Tappers (without clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cv_models)\n",
    "importlib.reload(plot_folds)\n",
    "\n",
    "n_permutations = 200\n",
    "\n",
    "# random_penalties = {'mean': [], 'lists': []}\n",
    "r_states = np.linspace(0, 1000, n_permutations).astype(int)\n",
    "# for random_shuffle in r_states: \n",
    "\n",
    "# CLassification Settings\n",
    "temp_data = cv_data  # data to use here\n",
    "clf_choice = 'RF'\n",
    "nFolds = 6\n",
    "mask_0 = False\n",
    "multiclass = True\n",
    "score_to_predict = 1\n",
    "\n",
    "y_model = temp_data.y.copy()\n",
    "if mask_0: # mask 0's to 1\n",
    "    y_model[y_model == 0] = 1\n",
    "    mc_labels = ['0-1', '2', '3-4']\n",
    "else:\n",
    "    mc_labels = ['0', '1', '2', '3-4']\n",
    "\n",
    "if not multiclass:\n",
    "    y_model = y_model == score_to_predict\n",
    "    to_plot = True\n",
    "\n",
    "    if score_to_predict == 1:\n",
    "        plot_thresholds = [.65, .7, .75]\n",
    "        roc_title = f'Identify UPDRS 0/1 vs Rest ({clf_choice})'\n",
    "\n",
    "    elif score_to_predict == 3:\n",
    "        plot_thresholds = [.25, .4, .5]\n",
    "        roc_title = f'Identify UPDRS 3-4 vs Rest ({clf_choice})'\n",
    "\n",
    "# # shuffle true y-labels\n",
    "# np.random.seed(random_shuffle)\n",
    "# np.random.shuffle(y_model)\n",
    "\n",
    "# print descriptives\n",
    "# n_samples = len(temp_data.ids)\n",
    "# print(f'Included # of traces: {n_samples}')\n",
    "# y_scores, counts = np.unique(y_model, return_counts=True)\n",
    "# for s, c in zip(y_scores, counts):\n",
    "#     print(f'\\tscore {s}: # {c} ({round(c / n_samples * 100)} %)')\n",
    "\n",
    "\n",
    "(y_pred_dict, y_proba_dict,\n",
    "y_true_dict, og_pred_idx\n",
    ") = cv_models.get_cvFold_predictions_dicts(\n",
    "    X_cv=temp_data.X,\n",
    "    y_cv=y_model,\n",
    "    cv_method=StratifiedKFold,\n",
    "    n_folds=nFolds,\n",
    "    clf=clf_choice,\n",
    "    verbose=False,\n",
    ")\n",
    "if to_plot and not multiclass: \n",
    "    plot_folds.plot_ROC_AUC_confMatrices_for_folds(\n",
    "        y_true_dict=y_true_dict,\n",
    "        y_proba_dict=y_proba_dict,\n",
    "        plot_thresholds=plot_thresholds,\n",
    "        roc_title=roc_title,\n",
    "        verbose=False,\n",
    "    )\n",
    "if multiclass:\n",
    "    cm = cv_models.multiclass_conf_matrix(\n",
    "        y_true=y_true_dict, y_pred=y_pred_dict,\n",
    "        labels=mc_labels,\n",
    "    )\n",
    "    # print(f'\\nConfusion Matrix:\\n{cm}')\n",
    "    mean_pen, std_pen, pen_list = cv_models.get_penalties_from_conf_matr(cm)\n",
    "    # print(f'mean UPDRS-penalty: {round(mean_pen, 2)}'\n",
    "    #         f' (+/- {round(std_pen, 2)})')\n",
    "    \n",
    "    # random_penalties['mean'].append(mean_pen)\n",
    "    # random_penalties['lists'].append(pen_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty alpha .05 cut off without distribution knowledge: 1.1336091549295775\n"
     ]
    }
   ],
   "source": [
    "penalties_full_chance = []\n",
    "true_labels = overall_perf['y_true'].values\n",
    "\n",
    "r_states = np.linspace(0, 1000, n_permutations).astype(int)\n",
    "\n",
    "for r_seed in r_states:\n",
    "    np.random.seed(r_seed)\n",
    "    random_labels = np.random.randint(0, 3 + 1, size=len(true_labels))\n",
    "    diffs = abs(true_labels - random_labels)\n",
    "    penalties_full_chance.append(diffs.mean())\n",
    "\n",
    "print(\n",
    "    'Penalty alpha .05 cut off without distribution'\n",
    "    f' knowledge: {np.mean(penalties_full_chance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_dir = os.path.join(\n",
    "    find_onedrive_path('results'),\n",
    "    'predictions', 'permutations')\n",
    "perm_fname = f'RF_full_dev_data_{n_permutations}perms_means.csv'\n",
    "mean_penalties = np.loadtxt(os.path.join(perm_dir, perm_fname))\n",
    "sign_05 = round(np.percentile(mean_penalties, 5), 2)\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.hist(mean_penalties)\n",
    "plt.title(f'Alpha .05 significance cut off: {sign_05}', size=14)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(sign_05, ymin=ymin, ymax=ymax, color='r', ls='--')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dataManagement)\n",
    "from retap_utils.utils_dataManagement import find_onedrive_path\n",
    "\n",
    "save_dir = os.path.join(\n",
    "    find_onedrive_path('results'),\n",
    "    'predictions', 'permutations')\n",
    "fname = f'RF_full_dev_data_{n_permutations}perms_lists'\n",
    "\n",
    "if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "np.savetxt(\n",
    "    os.path.join(save_dir, f'{fname}.csv'),\n",
    "    random_penalties['lists'], delimiter=',',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Clustering & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Candidate vetors based on descriptives and concept\n",
    "    - nTaps\n",
    "    - freq\n",
    "    - upVelo sum [std-dev + coefVar]\n",
    "    - impact RMS [coefVar + stddev]\n",
    "    - tapRMS and impactRMS [sum]\n",
    "    - \n",
    "- include per run (array tap-features): sum, mean, stddev, trend_slope\n",
    "\n",
    "- Cluster on UPDRS 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# try: K-shape (sklearn), Laio 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\retap\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(plot_cluster)\n",
    "\n",
    "n_clusters=4\n",
    "center_incl = 'all'\n",
    "sel_feats = True\n",
    "\n",
    "\n",
    "### VISUALISE AGAINST SUBS !! AND CONDITIONS\n",
    "\n",
    "\n",
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center=center_incl,\n",
    "    use_sel_fts=sel_feats,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "\n",
    "figname = (\n",
    "    f'retap_{n_clusters}clusters_'\n",
    "    f'{center_incl}'\n",
    ")\n",
    "if sel_feats: figname += '_selFeats'\n",
    "else: figname += '_allFeats'\n",
    "\n",
    "plot_cluster.plot_cluster_kMeans(\n",
    "    X=X, y=y,\n",
    "    n_clusters=n_clusters,\n",
    "    use_pca=True,\n",
    "    random_state=27,\n",
    "    figsave_name=figname,\n",
    "    figsave_dir=os.path.join(\n",
    "        utils_dataManagement.find_onedrive_path('figures'),\n",
    "        'clustering',\n",
    "    ),\n",
    "    show=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANOVA\n",
    "\n",
    "- normality assumption violated (Shapiro test highly significant)\n",
    "- for every a priori selected feature: present difference between sub-score-groups is a Kruskal-Wallis test (non-parametric One-Way ANOVA alternative)\n",
    "- differences between two sub groups within a feature is a non-parametric test of two groups of quantitative values (likely varying lengths): Mann-Whitney-U\n",
    "- in total: correct alpha for number of repeated measures on specific level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "for col in np.arange(X.shape[1]):\n",
    "    print(feats[col], shapiro(X[:, col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Multivariate linear model\n",
      "==============================================================\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "       Intercept        Value  Num DF  Den DF  F Value  Pr > F\n",
      "--------------------------------------------------------------\n",
      "          Wilks' lambda 0.1239 7.0000 365.0000 368.6918 0.0000\n",
      "         Pillai's trace 0.8761 7.0000 365.0000 368.6918 0.0000\n",
      " Hotelling-Lawley trace 7.0708 7.0000 365.0000 368.6918 0.0000\n",
      "    Roy's greatest root 7.0708 7.0000 365.0000 368.6918 0.0000\n",
      "--------------------------------------------------------------\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "         subscore        Value  Num DF  Den DF  F Value Pr > F\n",
      "--------------------------------------------------------------\n",
      "           Wilks' lambda 0.7803 7.0000 365.0000 14.6821 0.0000\n",
      "          Pillai's trace 0.2197 7.0000 365.0000 14.6821 0.0000\n",
      "  Hotelling-Lawley trace 0.2816 7.0000 365.0000 14.6821 0.0000\n",
      "     Roy's greatest root 0.2816 7.0000 365.0000 14.6821 0.0000\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "manova_df = pd.DataFrame(\n",
    "    data=stat_data,\n",
    "    columns=feats + ['subscore'],\n",
    ")\n",
    "maov = MANOVA.from_formula(\n",
    "    'nTaps + freq + mean_intraTapInt + coefVar_intraTapInt + IQR_jerkiness +'\n",
    "    ' mean_raise_velocity + mean_tapRMSnrm ~ subscore ',\n",
    "    # 'mean_jerkiness_smooth + IQR_jerkiness_smooth ~ subscore',\n",
    "    data=manova_df,\n",
    ")\n",
    "print(maov.mv_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "freq: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 3.8e-05)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.485159)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 0.00025)\n",
      "\n",
      "coefVar_intraTapInt: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 0.0)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.084536)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 4.8e-05)\n",
      "\n",
      "mean_jerkiness: \n",
      "\tGroup level sign. difference (Kruskal Test): False (p = 0.331604)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.375883)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): False (p = 0.140139)\n",
      "\n",
      "coefVar_jerkiness: \n",
      "\tGroup level sign. difference (Kruskal Test): False (p = 0.719329)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.507749)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): False (p = 0.490786)\n",
      "\n",
      "mean_tapRMSnrm: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 3e-06)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.017736)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 0.00162)\n",
      "\n",
      "coefVar_tapRMSnrm: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 3e-06)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.417794)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 4e-06)\n",
      "\n",
      "slope_tapRMSnrm: \n",
      "\tGroup level sign. difference (Kruskal Test): True (p = 1e-06)\n",
      "\n",
      "\tupdrs 0 vs 1 sign, (Spearman): False (p = 0.012758)\n",
      "\tupdrs 1 vs 2 sign, (Spearman): True (p = 0.000827)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "importlib.reload(pred_prep)\n",
    "\n",
    "mask_scores = True\n",
    "\n",
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center=center_incl,\n",
    "    use_sel_fts=sel_feats,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "n_groups = 5\n",
    "if mask_scores:\n",
    "    # UPDRS 4 -> 3 merge\n",
    "    mask = y == 4\n",
    "    y[mask] = 3\n",
    "    # UPDRS 0 -> 1 merge\n",
    "    mask = y == 0\n",
    "    y[mask] = 1\n",
    "\n",
    "    n_groups = 3\n",
    "\n",
    "stat_data = np.concatenate([X, y.reshape((len(y), 1))], axis=1)\n",
    "stat_df = pd.DataFrame(\n",
    "    data=stat_data,\n",
    "    columns=feats + ['subscore'],\n",
    ")\n",
    "\n",
    "stat_fts = [\n",
    "    'freq', 'coefVar_intraTapInt', 'mean_jerkiness', 'coefVar_jerkiness',\n",
    "    'mean_tapRMSnrm', 'coefVar_tapRMSnrm', 'slope_tapRMSnrm'\n",
    "]\n",
    "alpha = .05 / len(stat_fts)\n",
    "for ft in stat_fts:\n",
    "    tempft = stat_df[~np.isnan(stat_df[ft])]\n",
    "\n",
    "    \n",
    "    if mask_scores:\n",
    "        groups = [\n",
    "            tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "            for s in np.arange(1, n_groups + 1)\n",
    "        ]\n",
    "        krusk_stat, krusk_p = kruskal(\n",
    "            groups[0], groups[1], groups[2], \n",
    "        )\n",
    "    else:\n",
    "        groups = [\n",
    "            tempft[ft][tempft['subscore'] == s].reset_index(drop=True)\n",
    "            for s in np.arange(n_groups)\n",
    "        ]\n",
    "        krusk_stat, krusk_p = kruskal(\n",
    "            groups[0], groups[1], groups[2], \n",
    "            groups[3], groups[4]\n",
    "        )\n",
    "    print(f'\\n{ft}: \\n\\tGroup level sign. difference (Kruskal'\n",
    "        f' Test): {krusk_p < alpha} (p = {np.round(krusk_p, 6)})\\n')\n",
    "    for g in np.arange(n_groups - 1):\n",
    "\n",
    "        mnwu_rho, mnwu_p = mannwhitneyu(groups[g], groups[g + 1])\n",
    "        print(f'\\tupdrs {g} vs {g + 1} sign, (Mann-Whitney-U): '\n",
    "            f'{mnwu_p < (alpha / (n_groups - 1))} (p = {np.round(mnwu_p, 6)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "\n",
    "# UPDRS 4 -> 3 merge\n",
    "mask = y == 4\n",
    "y[mask] = 3\n",
    "# UPDRS 0 -> 1 merge\n",
    "mask = y == 0\n",
    "y[mask] = 1\n",
    "### 3c. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying UPDRS 0 - 1 - 2 - 3 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 12)\n",
      "0.19776827012025905\n",
      "[0.17021277 0.14893617 0.21276596 0.21276596 0.19148936 0.15217391\n",
      " 0.13043478 0.2173913  0.14893617 0.08510638 0.17021277 0.23404255\n",
      " 0.17021277 0.30434783 0.23913043 0.2826087  0.14893617 0.25531915\n",
      " 0.12765957 0.17021277 0.19148936 0.17391304 0.2173913  0.10869565\n",
      " 0.27659574 0.12765957 0.21276596 0.17021277 0.29787234 0.26086957\n",
      " 0.06521739 0.19565217 0.25531915 0.19148936 0.29787234 0.23404255\n",
      " 0.19148936 0.17391304 0.17391304 0.13043478 0.17021277 0.23404255\n",
      " 0.23404255 0.29787234 0.19148936 0.13043478 0.19565217 0.26086957\n",
      " 0.14893617 0.21276596 0.31914894 0.25531915 0.10638298 0.15217391\n",
      " 0.17391304 0.23913043 0.21276596 0.21276596 0.14893617 0.25531915\n",
      " 0.27659574 0.15217391 0.17391304 0.13043478 0.21276596 0.19148936\n",
      " 0.29787234 0.19148936 0.19148936 0.08695652 0.23913043 0.26086957\n",
      " 0.19148936 0.23404255 0.27659574 0.14893617 0.10638298 0.19565217\n",
      " 0.2173913  0.17391304]\n"
     ]
    }
   ],
   "source": [
    "traces, feats = pred_prep.select_traces_and_feats(\n",
    "    ftClass,\n",
    "    center='all',\n",
    "    use_sel_fts=True,\n",
    ")\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "print(X.shape)\n",
    "\n",
    "# use random outcome labels (equal distribution over scores)\n",
    "random_y = np.random.randint(0, 5, size=X.shape[0])\n",
    "y = random_y\n",
    "# use shuffled outcome labels (same distribution)\n",
    "np.random.seed(27)\n",
    "# np.random.shuffle(y)\n",
    "\n",
    "# UPDRS 4 -> 3 merge\n",
    "# mask = y == 4\n",
    "# y[mask] = 3\n",
    "# # UPDRS 0 -> 1 merge\n",
    "# mask = y == 0\n",
    "# y[mask] = 1\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X, y)\n",
    "\n",
    "#Define method to evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=10, random_state=1)\n",
    "\n",
    "#evaluate model\n",
    "scores = cross_val_score(lda, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores)) \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean Accuracy: 0.534068278805121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLassification Settings\n",
    "\n",
    "X, y = pred_prep.create_X_y_vectors(\n",
    "    ftClass,\n",
    "    incl_traces=traces,\n",
    "    incl_feats=feats,\n",
    "    to_norm=False,\n",
    ")\n",
    "# print(f'INCLUDED FEATURE SPACE: {X.shape}')\n",
    "\n",
    "nFolds = 10\n",
    "\n",
    "# UPDRS 4 -> 3 merge\n",
    "mask = y == 4\n",
    "y[mask] = 3\n",
    "# UPDRS 0 -> 1 merge\n",
    "mask = y == 0\n",
    "y[mask] = 1\n",
    "\n",
    "\n",
    "# Shuffle order\n",
    "# allData = np.hstack((X, y))\n",
    "# X_shf = allData[:, :14]\n",
    "# y_shf = allData[:, 14]\n",
    "\n",
    "# np.random.shuffle(allData)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds,)\n",
    "skf.get_n_splits(X, y)\n",
    "# clf = LinearSVC(\n",
    "#         penalty='l2',\n",
    "#     C=1.0,\n",
    "#     multi_class='ovr',\n",
    "#     max_iter=10000,\n",
    "# )\n",
    "clf = LogisticRegression(\n",
    "    random_state=0, \n",
    "    solver='liblinear',\n",
    "    multi_class='ovr',\n",
    ")\n",
    "\n",
    "shuffled_accs = []\n",
    "np.random.seed(27)\n",
    "# for r_state in np.random.randint(100, size=1000):\n",
    "\n",
    "    # np.random.seed(r_state)\n",
    "    # # y_shuffled = y.copy()\n",
    "    # # np.random.shuffle(y_shuffled)\n",
    "    # np.random.shuffle(y)\n",
    "\n",
    "y_pred, y_true = {}, {}\n",
    "all_accs = []\n",
    "for F, (train_index, test_index) in enumerate(\n",
    "    skf.split(X, y)\n",
    "):\n",
    "    # print(f'\\nLinear Support Vector, fold #{F}')\n",
    "    # print(f'\\nLogistic Regression, fold #{F}')\n",
    "    # print(\n",
    "    #     f'\\tn train: {train_index.shape}, '\n",
    "    #     f'n test: {test_index.shape}')\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # print('\\tcount for y-labels in test set\\n',\n",
    "    #     np.array(np.unique(y_test, return_counts=True)).T)\n",
    "    \n",
    "    clf = clf\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    acc = clf.score(X=X_test, y=y_test)\n",
    "    # print(\n",
    "    #     f'accuracy for Fold {F}: {acc}')\n",
    "    all_accs.append(acc)\n",
    "    \n",
    "    # save predictions for posthoc analysis and conf matrix\n",
    "    y_pred[F] = clf.predict(X=X_test)\n",
    "    y_true[F] = y_test\n",
    "    # print(multilabel_confusion_matrix(y_true[F], y_pred[F]))\n",
    "\n",
    "        \n",
    "print(f'Overall mean Accuracy: {np.mean(all_accs)}\\n')\n",
    "    # shuffled_accs.append(np.mean(all_accs))\n",
    "\n",
    "# print('grand mean', np.mean(shuffled_accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean Accuracy: 0.4047700754975978\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall mean Accuracy: {np.mean(all_accs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Classifying (UPDRS 0 or 4 vs The Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of UPDRS subscore 0 versus thre rest\n",
      "\n",
      "Linear Support Vector, fold #0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7d/4ptht2m910d1y872jrgp9cq40000gp/T/ipykernel_10037/2107056001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {clf.score(X=X_test, y=y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# for own scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecog_dysk/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     ]:\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# CLassification Settings\n",
    "nFolds = 4\n",
    "score_to_predict = 0\n",
    "\n",
    "# Shuffle order\n",
    "X = Xdf.values\n",
    "y_bool = y == score_to_predict\n",
    "\n",
    "allData = np.hstack((X, y_bool))\n",
    "\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(allData)\n",
    "\n",
    "X_shf = allData[:, :14]\n",
    "y_shf = allData[:, 14]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds,)\n",
    "skf.get_n_splits(X_shf, y_shf)\n",
    "\n",
    "y_pred, y_true = {}, {}\n",
    "print(\n",
    "    'Classification of UPDRS subscore '\n",
    "    f'{score_to_predict} versus thre rest')\n",
    "for F, (train_index, test_index) in enumerate(\n",
    "    skf.split(X, y)\n",
    "):\n",
    "    print(f'\\nLinear Support Vector, fold #{F}')\n",
    "\n",
    "    X_train, X_test = X_shf[train_index], X_shf[test_index]\n",
    "    y_train, y_test = y_shf[train_index], y_shf[test_index]\n",
    "\n",
    "    clf = LinearSVC(penalty='l2', C=1.0,)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    print(f'Accuracy: {clf.score(X=X_test, y=y_test)}')\n",
    "    # for own scoring\n",
    "    y_pred[F] = clf.predict(X=X_test)\n",
    "    y_true[F] = y_test\n",
    "    print(classification_report(y_true[F], y_pred[F]))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23a308fb4398211655e9950c8371f856de701ec09eac61c96054832e4a49057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
